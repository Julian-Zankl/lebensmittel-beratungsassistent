{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3f7335d9",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "109c73aa",
   "metadata": {},
   "source": [
    "### üõ†Ô∏è Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ebdd35f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "from aiworkshop_utils.standardlib_imports import os, json, base64, logging, Optional, List, Literal, pprint, glob, asyncio, datetime, date, time, timezone, ZoneInfo, uuid, dataclass\n",
    "from aiworkshop_utils.thirdparty_imports import AutoTokenizer, load_dotenv, requests, BaseModel, Field, pd, cosine_similarity, plt, np, DataType, MilvusClient, DDGS, rprint\n",
    "from aiworkshop_utils.custom_utils import show_pretty_json, encode_image\n",
    "from aiworkshop_utils.jupyter_imports import Markdown, HTML, JSON, display, widgets\n",
    "from aiworkshop_utils.openai_imports import OpenAI, Agent, Runner, InputGuardrail, GuardrailFunctionOutput, InputGuardrailTripwireTriggered, OpenAIChatCompletionsModel, AsyncOpenAI, set_tracing_disabled, ModelSettings, function_tool, trace, ResponseContentPartDoneEvent, ResponseTextDeltaEvent, RawResponsesStreamEvent, TResponseInputItem, ItemHelpers, MessageOutputItem, RunContextWrapper, input_guardrail, output_guardrail\n",
    "from aiworkshop_utils import config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "54f6d533",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard library imports\n",
    "import os\n",
    "import json\n",
    "import base64\n",
    "import logging\n",
    "from typing import Optional, List, Dict, Any, Union, Literal\n",
    "import asyncio\n",
    "from datetime import datetime, date, time, timezone\n",
    "from zoneinfo import ZoneInfo\n",
    "import uuid\n",
    "from dataclasses import dataclass\n",
    "from pprint import pprint\n",
    "from glob import glob\n",
    "\n",
    "# Third-party imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import requests\n",
    "from dotenv import load_dotenv\n",
    "from pydantic import BaseModel, Field\n",
    "from rich import print as rprint\n",
    "from tqdm import tqdm\n",
    "from pymilvus import DataType, MilvusClient, Collection\n",
    "from duckduckgo_search import DDGS\n",
    "\n",
    "# Document processing imports\n",
    "from docling.backend.pypdfium2_backend import PyPdfiumDocumentBackend\n",
    "from docling.chunking import HybridChunker\n",
    "from docling.datamodel.base_models import InputFormat\n",
    "from docling.datamodel.pipeline_options import (\n",
    "    AcceleratorDevice,\n",
    "    AcceleratorOptions,\n",
    "    PdfPipelineOptions,\n",
    ")\n",
    "from docling.document_converter import (\n",
    "    DocumentConverter,\n",
    "    PdfFormatOption,\n",
    "    WordFormatOption,\n",
    ")\n",
    "from docling.pipeline.simple_pipeline import SimplePipeline\n",
    "\n",
    "# OpenAI and Agent imports\n",
    "from openai import OpenAI, AsyncOpenAI\n",
    "from agents import (\n",
    "    Agent,\n",
    "    GuardrailFunctionOutput,\n",
    "    InputGuardrail,\n",
    "    InputGuardrailTripwireTriggered,\n",
    "    ModelSettings,\n",
    "    OpenAIChatCompletionsModel,\n",
    "    Runner,\n",
    "    function_tool,\n",
    "    set_tracing_disabled,\n",
    "    trace,\n",
    "    RawResponsesStreamEvent,\n",
    "    ItemHelpers, \n",
    "    MessageOutputItem,\n",
    "    RunContextWrapper,\n",
    "    input_guardrail,\n",
    "    output_guardrail\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "996a3264",
   "metadata": {},
   "source": [
    "### Pydantic Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "014197e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class HealthData(BaseModel):\n",
    "    age: int = Field(description=\"Age in years\")\n",
    "    gender: str = Field(description=\"e.g. male, female, diverse\")\n",
    "    weight: float = Field(description=\"Weight in kg\")   \n",
    "    height: float = Field(description=\"Height in cm\")\n",
    "    allergies: Optional[str] = Field(description=\"e.g. nuts, gluten\")\n",
    "    eating_habits: str = Field(description=\"e.g. vegetarian, vegan, omnivore, paleo\")\n",
    "    goal: str = Field(description=\"e.g. weight loss, muscle gain, maintenance\")\n",
    "    activity_level: str = Field(description=\"e.g. sedentary, lightly active, moderately active, very active\")\n",
    "    timeCooking: int = Field(description=\"Time spent cooking per day in minutes\")\n",
    "    healthCondition: Optional[str] = Field(description=\"e.g. diabetes, hypertension\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5a84e0c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Beispiel: Formularinstanz erzeugen und ausgeben\n",
    "sample_form = HealthData(\n",
    "    age=30,\n",
    "    gender=\"m√§nnlich\",\n",
    "    weight=85.0,\n",
    "    height=180.0,\n",
    "    allergies=\"keine\",\n",
    "    eating_habits=\"omnivor\",\n",
    "    goal=\"Muskelaufbau\",\n",
    "    activity_level=\"sportlich\",\n",
    "    timeCooking=45,\n",
    "    healthCondition=\"leicht erh√∂hter Blutdruck\"\n",
    ")\n",
    "\n",
    "prompt1 = \"\"\"\n",
    "Ich bin 20 Jahre alt, m√§nnlich, wiege 85kg und bin 1,80m gro√ü. \n",
    "Ich bin laktoseintolerant und esse gerne vegan. \n",
    "Mein Ziel ist es, mehr Muskeln aufzubauen, weshalb ich moderat Sport betreibe. \n",
    "F√ºr das t√§gliche Kochen plane ich maximal 2 Stunden (120 min) ein. \n",
    "Leider bin ich auch Diabetiker, weshalb ich auch auf meinen Zuckerhaushalt achten muss. \n",
    "Welche Di√§tform kannst du mir empfehlen?\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baf9cfb4",
   "metadata": {},
   "source": [
    "## Document"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b111527d",
   "metadata": {},
   "source": [
    "### Parsing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "82829ade",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DocumentParser:\n",
    "    def __init__(self, converter):\n",
    "        self.converter = converter\n",
    "\n",
    "    def parse(self, file_path: str, options: dict = None):\n",
    "        print(f\"Converting document: {file_path}\")\n",
    "        result = self.converter.convert(file_path)\n",
    "        return result.document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a59be2e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converting document: assets/health_data.pdf\n"
     ]
    }
   ],
   "source": [
    "source = \"assets/health_data.pdf\"\n",
    "\n",
    "my_processor = DocumentParser(DocumentConverter())\n",
    "processor_result = my_processor.parse(source)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb7db28c",
   "metadata": {},
   "source": [
    "### Chunking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "54319766",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DocumentChunker:\n",
    "    def __init__(self, tokenizer: str = \"sentence-transformers/all-MiniLM-L6-v2\"):\n",
    "        self.tokenizer = tokenizer\n",
    "        self.chunker = HybridChunker(tokenizer=tokenizer)\n",
    "\n",
    "    def chunk(self, document, options: dict = None):\n",
    "        print(\"Chunking document...\")\n",
    "        chunks = list(self.chunker.chunk(document))\n",
    "        print(f\"Created {len(chunks)} chunks\")\n",
    "        return chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2ceb9f41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunking document...\n",
      "Created 98 chunks\n"
     ]
    }
   ],
   "source": [
    "my_chunker = DocumentChunker()\n",
    "chunker_result = my_chunker.chunk(processor_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38acdb18",
   "metadata": {},
   "source": [
    "### Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8815ea90",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DocumentEmbedder:\n",
    "    def __init__(self, url, model_name):\n",
    "        self.url = url\n",
    "        self.model_name = model_name\n",
    "\n",
    "    def _post_request(self, texts):\n",
    "        if isinstance(texts, str):\n",
    "            texts = [texts]\n",
    "        response = requests.post(\n",
    "            self.url,\n",
    "            json={\n",
    "                \"model\": self.model_name,\n",
    "                \"input\": texts\n",
    "            }\n",
    "        )\n",
    "        response.raise_for_status()\n",
    "        return response.json()\n",
    "\n",
    "    def get_embeddings(self, texts):\n",
    "        response = self._post_request(texts)\n",
    "        embeddings = response[\"embeddings\"]\n",
    "        if isinstance(texts, str) or len(embeddings) == 1:\n",
    "            return embeddings[0]\n",
    "        return embeddings\n",
    "\n",
    "    def get_full_response(self, texts):\n",
    "        return self._post_request(texts)\n",
    "\n",
    "    def embed(self, chunks):\n",
    "        texts = [chunk.text for chunk in chunks]\n",
    "        return self.get_embeddings(texts)\n",
    "    \n",
    "    def get_prepared_data_for_indexing(self, chunks):\n",
    "        embedding_result = self.embed(chunks)\n",
    "        data = []\n",
    "        for chunk, vector in zip(chunks, embedding_result):\n",
    "            headings = \"\"\n",
    "            page_info = \"\"\n",
    "            if hasattr(chunk, \"meta\") and chunk.meta:\n",
    "                headings_list = getattr(chunk.meta, \"headings\", [])\n",
    "                if headings_list:\n",
    "                    headings = \" > \".join(headings_list)\n",
    "                page_info = getattr(chunk.meta, \"page_info\", \"\")\n",
    "            data.append({\n",
    "                \"vector\": vector,\n",
    "                \"text\": chunk.text,\n",
    "                \"headings\": headings,\n",
    "                \"page_info\": page_info\n",
    "            })\n",
    "        return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8b18265a",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_embedder = DocumentEmbedder(url=config.OAPI_EMBED_URL, model_name=config.OMODEL_NOMIC)\n",
    "embedding_result = my_embedder.embed(chunker_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "29e92275",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "98\n",
      "[0.029407937, -0.007725332, -0.16320756, -0.026395265, 0.03437459, -0.03793293, -0.049199972, -0.0077174124, -0.021334266, -0.021033404, -0.03016901, -8.664924e-05, 0.07509571, 0.085213125, 0.008133813, -0.010943744, -0.016439993, -0.043249737, -0.024111161, 0.010377481, 0.05121823, 0.03195553, -0.009324543, -0.0596079, 0.025305636, 0.0256475, -0.0048430045, 0.002121591, -0.04049873, -0.0050582634, 0.0074854787, 0.00644616, 0.0057679694, -0.00082253775, 7.414384e-05, -0.075304456, 0.016309405, 0.005631348, -0.024207316, 0.015241426, 0.02103698, -0.028154803, 0.001779003, -0.060931705, -0.008009651, 0.0022962943, -0.04469948, -0.0023547928, 0.07105846, -0.06433149, 0.0021380114, 0.043761663, -0.015382296, 0.020869996, 0.078693844, -0.036903802, -0.07706409, -0.05066658, -0.013687871, -0.053277984, 0.021080783, 0.078174956, -0.065949656, 0.014262262, 0.034166154, -0.026743347, -0.06996673, 0.056965724, 0.008793368, 0.0023380641, 0.0127667915, -0.009422646, 0.035293605, 0.0011332023, 0.012085321, 0.0032955706, -0.03067795, -0.015514455, -0.005742442, 0.020019384, 0.043317404, -0.007972036, 0.08781485, 0.025050651, 0.039467987, -0.04181522, 0.0030791461, -0.014564847, -0.018549956, 0.04796158, 0.040712107, -0.0183402, -0.04452932, -0.012310383, -0.050932866, 0.021621997, 0.026462685, 0.0043404773, -0.033293564, -0.0074260253, -0.021338912, -0.031613886, 0.023656787, 0.03180317, 0.03543082, -0.018963678, 0.053749617, 0.00028084626, 0.03254872, -0.03823036, -0.010003866, -0.013097437, -0.029635046, 0.010194087, 0.00082847825, 0.035130646, 0.045040913, -0.049588654, 0.0028047701, 0.035316437, -0.00041335777, -0.033610847, 0.054004576, 0.01272777, 0.072976425, -0.025634993, -0.017341068, -0.00026181553, 0.054719187, 0.004118561, -0.021156965, 0.048222583, -0.0031097431, 0.007371559, 0.045893487, 0.026397018, -0.033798166, 0.011528526, 0.036827207, -0.016157897, 0.0691757, -0.0012850834, -0.011016832, 0.0036784303, -0.021032035, -0.060132433, 0.024683777, -0.024331918, 0.036257472, 0.0009748832, -0.0057213204, 0.008815341, -0.034946144, 0.048431654, 0.008496406, -0.044080548, -0.002988508, 0.010389171, 0.042969346, 0.0365388, 0.0447539, 0.022509899, -0.08943115, 0.06074693, 0.014804211, 0.048884913, -0.00017130918, 0.010542422, 0.05270014, -0.003952049, -0.018306509, -0.016163344, -0.038659334, -0.006969938, 0.05115302, -0.029457591, 0.061232872, -0.009260835, 0.01460364, 0.0029352417, 0.01203831, -0.035815764, 0.045794327, 0.010755899, -0.030854004, -0.009106634, 0.056717712, -0.09027651, -0.029485919, -0.04255993, 7.079088e-05, 0.031238843, -0.024529966, 0.011220717, -0.056082126, 0.021120429, 0.06298886, 0.044791527, 0.018154163, -0.049009267, 0.017277073, 0.019606674, -0.043889128, 0.02817578, -0.016701536, 0.026198149, -0.012213357, 0.04599098, 0.030495688, -0.014129395, 0.034786433, 0.00289708, 0.08828827, -0.007665161, 0.033395473, -0.017741006, -0.027274635, -0.02600581, 0.018069796, -0.0321468, 0.0065758834, -0.021943161, 0.035607453, -0.03377414, 0.0009224115, -0.00546263, 0.015971553, 0.043743186, -0.043980952, 0.013414536, -0.021234736, -0.110808276, 0.042699408, 0.01628698, 0.027510738, 0.043213207, -0.0057851854, 0.036816105, 0.04191818, 0.11669084, -0.03137476, -0.016488992, 0.028628366, -0.01248939, -0.023182703, 0.021632997, 0.029221758, -0.0685579, -0.059915543, 0.06567977, -0.017236225, -0.033557374, 0.06403909, 0.021848429, 0.008676496, -0.016373089, -0.07126915, -0.06785628, 0.027809696, 0.0653582, 0.010756319, 0.015193697, 0.020997912, 0.008287095, -0.020135835, -0.013231382, -0.057514466, -0.055808395, 0.030209506, -0.043050095, 0.018379139, -0.008233968, -0.042705715, 0.030356914, -0.032934517, -0.0005073711, 0.00838097, -0.006638592, 0.0069507384, -0.016150106, -0.01234571, -0.031830132, 0.0336523, 0.05037118, 0.0076888395, 0.053071104, -0.012516367, -0.00150411, 0.033312846, -0.0044660154, 0.040677223, 0.014039548, -0.02546052, -0.018671814, 0.02337426, -0.0023498624, -0.0017184274, -0.010976461, -0.030308835, -0.028100306, -0.012786779, -0.017899822, 0.04310736, 0.019320002, -0.020934215, -0.024483375, 0.011548094, -0.052243974, 0.007944708, 0.022638945, -0.03714605, -0.025166597, -0.10377337, -0.0050065727, -0.027432943, 0.048662547, 0.07183706, -0.0077195396, 0.041086677, -0.016921353, 0.050116226, -0.018716628, -0.020067144, -0.08773502, 0.05917639, 0.070471816, -0.016274195, 0.03334974, 0.00800244, -0.031783734, 0.027860986, 0.03673633, 0.010713032, -0.062163305, -0.054904755, 0.042402294, -0.041911013, -0.021074565, 0.037030187, 0.024733212, 0.08196268, -0.018896261, -0.040545687, -0.043809816, -0.005257656, -0.015253032, -0.0104989605, -0.028617624, 0.036266066, 0.0011672134, 0.03442261, 0.05496268, -0.038570642, -0.046424508, -0.007848492, -0.034314983, 0.024993757, 0.048952505, 0.055913538, 0.015368481, 0.0003359329, -0.007859356, -0.03436812, -0.0028785614, -0.04849269, -0.032183237, 0.061296612, -0.021020371, -0.017200202, 0.021210872, 0.029847026, -0.020521518, 0.00035071303, 0.0022590074, 0.013532903, 0.010561808, -0.043468952, -0.015365657, -0.034262538, 0.016523058, 0.029548803, -0.007206528, -0.00089950976, 0.03927121, 0.042269558, -0.011749796, 0.046482682, -0.0050926157, -0.019881915, -0.00021431618, 0.028735206, -0.064833015, 0.0053623226, -0.0632388, 0.033312988, 0.0143272355, -0.022734664, 0.08825671, -0.013386516, 0.046523336, -0.012508615, -0.020965904, 0.015684333, -0.008157731, 0.019549267, 0.0531791, -0.04437503, -0.023543749, 0.028898204, -0.0135529665, 0.06010788, 0.05856958, -0.013769869, -0.03329083, 0.018585617, -0.020956345, 0.05213172, -0.060742512, 0.000556562, 0.06212322, 0.029065557, -0.006541772, 0.016302833, 0.021648517, -0.013489804, 0.028413132, 0.044849988, 0.007716326, 0.006571826, 0.0016023942, 0.05257762, 0.025531225, 0.049370557, -0.047078475, -0.0055675367, 0.045740362, -0.006289533, -0.01853867, -0.053461306, 0.020650592, 0.0032677508, -0.007474013, -0.0070247194, -0.047180317, 0.019476827, 0.035205483, 0.0065395706, -0.015353295, -0.01996687, 0.05767092, 0.011019773, 0.021002842, 0.018237635, -0.02322536, 0.0743443, -0.0067207078, 0.001719521, 0.003097193, -0.015995396, 0.056165468, 0.016530346, 0.02278677, -0.011639266, 0.033604246, -0.005484241, -0.008179427, 0.006437233, 0.009859413, 0.0058089322, -0.003004451, -0.031272896, 0.01951176, -0.02244156, -0.0007966452, -0.014868322, -0.013613085, -0.046897493, -0.009464215, -0.004882751, 0.067080334, -0.00967406, -0.05804073, -0.04735992, -0.042828742, 0.041059714, 0.030207371, 0.008116663, -0.03271577, 0.040146895, -0.0046853395, 0.08978497, 0.03983929, 0.031601556, -0.012560153, -0.07478509, 0.036060534, -0.02661313, -0.052547265, 0.06006379, 0.020274777, 0.05962854, 0.037343368, 0.00016860022, -0.05548778, 0.0058245244, -0.024818242, 0.048478298, -0.045036588, -0.06077684, 0.027391678, -0.024977801, -0.0130811855, -0.013756657, 0.037051074, 0.0020198284, -0.015468537, 0.034008693, -0.012375112, -0.026629096, -0.024138525, -0.0028480745, 0.022095049, 0.028037572, -0.0022509508, -0.07749398, 0.005022982, -0.00727295, -0.0068259165, 0.033115737, 0.0199505, 0.02114185, -0.02685578, -0.0018063094, -0.028142417, 0.032107648, -0.0051912, -0.017426535, -0.02652257, 0.050899137, 0.07368626, -0.05223529, 0.017580785, -0.037041664, 0.044566315, 0.018671582, -0.037815716, 0.011987722, 0.045169678, 0.0018121509, -0.054195236, 0.040377054, -0.03560927, 0.028140383, -0.05785241, 0.0224414, -0.01723669, 0.0561466, -0.055736516, 0.05304633, -0.022575628, 0.0052431994, -0.0042948127, 0.02436946, 0.0022056433, -0.01979279, 0.015822545, -0.008147554, -0.07423585, -0.03339149, 0.013066235, -0.01187028, -0.020151962, -0.06850732, -0.008372619, 0.024413073, 0.020091904, 0.020336445, 0.012789065, -0.06764696, -0.045821164, -0.0055136047, 0.0047791307, 0.0031694137, 0.02522163, -0.04401261, 0.012363201, -0.037120275, 0.0008360032, 0.011992481, -0.043828662, 0.026020128, 0.0042924234, -0.011801815, 0.013763202, -0.028328393, -0.023023061, 0.0053759757, 0.0082407, -0.00683523, -0.03910741, -0.011131156, -0.04065926, 0.062105477, -0.030005787, 0.008815181, -0.0068519283, 0.02996907, 0.046584453, -0.005073496, -0.0556667, 0.02273535, 0.049004138, -0.071780995, -0.017514545, 0.035166133, -0.03701806, 0.027807051, 0.0067200083, 0.01502184, -0.07308113, -0.01565129, 0.006448082, 0.0033324594, -0.07387746, -0.034777664, -0.025501003, -0.057104725, -0.055287365, -0.048452098, 0.024113743, 0.04658167, -0.022405125, -0.06267569, -0.004570461, -0.059221018, 0.052694935, -0.018907353, 0.052803356, 0.009114983, 0.008847871, 0.017884597, -0.012461748, 0.007115059, 0.06514109, 0.03851582, 0.0010109595, -0.02679693, 0.0440594, 0.033150308, -0.03787282, 0.045454856, 0.018557783, 0.04423571, 0.009434926, -0.018786436, 0.011439567, -0.010121315, -0.013313844, -0.079615265, -0.06944216, 0.028278736, -0.0075909663, -0.02463477, -0.039142255, 0.00896758, -0.062434103, 0.020346908, 0.00041840403, 0.0032588828, 0.0013163894, 0.0139276525, -0.059302736, 0.0017989055, 0.0050368253, -0.036957737, 0.05609387, 0.027446913, 0.048582558, 0.00085496495, 0.026958888, 0.044498097, 0.07772627, 0.008387499, -0.0303049, -0.059627995, -0.054744348, 0.00859041, -0.0057558618, -0.034558408, -0.06779239, -0.038804088, -0.022811249, -0.003363676, -0.03402216, -0.041637838, -0.00330985, -0.0028770245, -0.04236713, -0.03326566, 0.04482313, 0.019490544, -0.0040578675, 0.016802287, -0.0039889435, 0.021772845, -0.043549962, 0.020313663, 0.03430936, -0.023447376, -0.02066283, 0.039019875, -0.016220504, -0.04215773, 0.021813728, -0.065994024, 0.07613311, 0.011731492, -0.008362567, 0.00012437502, 0.033292428, 0.06682148, -0.013518166, -0.1006325, -0.04644204, -0.01334807, 0.076750234, 0.018476246, -0.0517865, 0.07000404, 0.022649882, 0.022437468, 0.032241434, 0.008218156, 0.0071493867, -0.013493118, -0.01979121, -0.029615989, -0.0347772, -0.0017923745, -0.025104601, 0.008120665, 0.047571316, 0.03767663, 0.050216496, -0.029191645, -0.03281201, -0.0031025563, -0.034206156, 0.008791988, -0.016895216, -0.006913128, -0.04897359, 0.017669087, 0.0008898749, -0.047825992, 0.034203783, -0.045691345, 0.0274288, 0.08153559, 0.038468108, 0.0029880963, -0.02187591, 0.025951318, -0.015224254, -0.051080674, 0.0028201214, -0.011769741, -0.0447073]\n"
     ]
    }
   ],
   "source": [
    "print(len(embedding_result))\n",
    "print(embedding_result[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0e920e3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'vector': [0.029407937, -0.007725332, -0.16320756, -0.026395265, 0.03437459, -0.03793293, -0.049199972, -0.0077174124, -0.021334266, -0.021033404, -0.03016901, -8.664924e-05, 0.07509571, 0.085213125, 0.008133813, -0.010943744, -0.016439993, -0.043249737, -0.024111161, 0.010377481, 0.05121823, 0.03195553, -0.009324543, -0.0596079, 0.025305636, 0.0256475, -0.0048430045, 0.002121591, -0.04049873, -0.0050582634, 0.0074854787, 0.00644616, 0.0057679694, -0.00082253775, 7.414384e-05, -0.075304456, 0.016309405, 0.005631348, -0.024207316, 0.015241426, 0.02103698, -0.028154803, 0.001779003, -0.060931705, -0.008009651, 0.0022962943, -0.04469948, -0.0023547928, 0.07105846, -0.06433149, 0.0021380114, 0.043761663, -0.015382296, 0.020869996, 0.078693844, -0.036903802, -0.07706409, -0.05066658, -0.013687871, -0.053277984, 0.021080783, 0.078174956, -0.065949656, 0.014262262, 0.034166154, -0.026743347, -0.06996673, 0.056965724, 0.008793368, 0.0023380641, 0.0127667915, -0.009422646, 0.035293605, 0.0011332023, 0.012085321, 0.0032955706, -0.03067795, -0.015514455, -0.005742442, 0.020019384, 0.043317404, -0.007972036, 0.08781485, 0.025050651, 0.039467987, -0.04181522, 0.0030791461, -0.014564847, -0.018549956, 0.04796158, 0.040712107, -0.0183402, -0.04452932, -0.012310383, -0.050932866, 0.021621997, 0.026462685, 0.0043404773, -0.033293564, -0.0074260253, -0.021338912, -0.031613886, 0.023656787, 0.03180317, 0.03543082, -0.018963678, 0.053749617, 0.00028084626, 0.03254872, -0.03823036, -0.010003866, -0.013097437, -0.029635046, 0.010194087, 0.00082847825, 0.035130646, 0.045040913, -0.049588654, 0.0028047701, 0.035316437, -0.00041335777, -0.033610847, 0.054004576, 0.01272777, 0.072976425, -0.025634993, -0.017341068, -0.00026181553, 0.054719187, 0.004118561, -0.021156965, 0.048222583, -0.0031097431, 0.007371559, 0.045893487, 0.026397018, -0.033798166, 0.011528526, 0.036827207, -0.016157897, 0.0691757, -0.0012850834, -0.011016832, 0.0036784303, -0.021032035, -0.060132433, 0.024683777, -0.024331918, 0.036257472, 0.0009748832, -0.0057213204, 0.008815341, -0.034946144, 0.048431654, 0.008496406, -0.044080548, -0.002988508, 0.010389171, 0.042969346, 0.0365388, 0.0447539, 0.022509899, -0.08943115, 0.06074693, 0.014804211, 0.048884913, -0.00017130918, 0.010542422, 0.05270014, -0.003952049, -0.018306509, -0.016163344, -0.038659334, -0.006969938, 0.05115302, -0.029457591, 0.061232872, -0.009260835, 0.01460364, 0.0029352417, 0.01203831, -0.035815764, 0.045794327, 0.010755899, -0.030854004, -0.009106634, 0.056717712, -0.09027651, -0.029485919, -0.04255993, 7.079088e-05, 0.031238843, -0.024529966, 0.011220717, -0.056082126, 0.021120429, 0.06298886, 0.044791527, 0.018154163, -0.049009267, 0.017277073, 0.019606674, -0.043889128, 0.02817578, -0.016701536, 0.026198149, -0.012213357, 0.04599098, 0.030495688, -0.014129395, 0.034786433, 0.00289708, 0.08828827, -0.007665161, 0.033395473, -0.017741006, -0.027274635, -0.02600581, 0.018069796, -0.0321468, 0.0065758834, -0.021943161, 0.035607453, -0.03377414, 0.0009224115, -0.00546263, 0.015971553, 0.043743186, -0.043980952, 0.013414536, -0.021234736, -0.110808276, 0.042699408, 0.01628698, 0.027510738, 0.043213207, -0.0057851854, 0.036816105, 0.04191818, 0.11669084, -0.03137476, -0.016488992, 0.028628366, -0.01248939, -0.023182703, 0.021632997, 0.029221758, -0.0685579, -0.059915543, 0.06567977, -0.017236225, -0.033557374, 0.06403909, 0.021848429, 0.008676496, -0.016373089, -0.07126915, -0.06785628, 0.027809696, 0.0653582, 0.010756319, 0.015193697, 0.020997912, 0.008287095, -0.020135835, -0.013231382, -0.057514466, -0.055808395, 0.030209506, -0.043050095, 0.018379139, -0.008233968, -0.042705715, 0.030356914, -0.032934517, -0.0005073711, 0.00838097, -0.006638592, 0.0069507384, -0.016150106, -0.01234571, -0.031830132, 0.0336523, 0.05037118, 0.0076888395, 0.053071104, -0.012516367, -0.00150411, 0.033312846, -0.0044660154, 0.040677223, 0.014039548, -0.02546052, -0.018671814, 0.02337426, -0.0023498624, -0.0017184274, -0.010976461, -0.030308835, -0.028100306, -0.012786779, -0.017899822, 0.04310736, 0.019320002, -0.020934215, -0.024483375, 0.011548094, -0.052243974, 0.007944708, 0.022638945, -0.03714605, -0.025166597, -0.10377337, -0.0050065727, -0.027432943, 0.048662547, 0.07183706, -0.0077195396, 0.041086677, -0.016921353, 0.050116226, -0.018716628, -0.020067144, -0.08773502, 0.05917639, 0.070471816, -0.016274195, 0.03334974, 0.00800244, -0.031783734, 0.027860986, 0.03673633, 0.010713032, -0.062163305, -0.054904755, 0.042402294, -0.041911013, -0.021074565, 0.037030187, 0.024733212, 0.08196268, -0.018896261, -0.040545687, -0.043809816, -0.005257656, -0.015253032, -0.0104989605, -0.028617624, 0.036266066, 0.0011672134, 0.03442261, 0.05496268, -0.038570642, -0.046424508, -0.007848492, -0.034314983, 0.024993757, 0.048952505, 0.055913538, 0.015368481, 0.0003359329, -0.007859356, -0.03436812, -0.0028785614, -0.04849269, -0.032183237, 0.061296612, -0.021020371, -0.017200202, 0.021210872, 0.029847026, -0.020521518, 0.00035071303, 0.0022590074, 0.013532903, 0.010561808, -0.043468952, -0.015365657, -0.034262538, 0.016523058, 0.029548803, -0.007206528, -0.00089950976, 0.03927121, 0.042269558, -0.011749796, 0.046482682, -0.0050926157, -0.019881915, -0.00021431618, 0.028735206, -0.064833015, 0.0053623226, -0.0632388, 0.033312988, 0.0143272355, -0.022734664, 0.08825671, -0.013386516, 0.046523336, -0.012508615, -0.020965904, 0.015684333, -0.008157731, 0.019549267, 0.0531791, -0.04437503, -0.023543749, 0.028898204, -0.0135529665, 0.06010788, 0.05856958, -0.013769869, -0.03329083, 0.018585617, -0.020956345, 0.05213172, -0.060742512, 0.000556562, 0.06212322, 0.029065557, -0.006541772, 0.016302833, 0.021648517, -0.013489804, 0.028413132, 0.044849988, 0.007716326, 0.006571826, 0.0016023942, 0.05257762, 0.025531225, 0.049370557, -0.047078475, -0.0055675367, 0.045740362, -0.006289533, -0.01853867, -0.053461306, 0.020650592, 0.0032677508, -0.007474013, -0.0070247194, -0.047180317, 0.019476827, 0.035205483, 0.0065395706, -0.015353295, -0.01996687, 0.05767092, 0.011019773, 0.021002842, 0.018237635, -0.02322536, 0.0743443, -0.0067207078, 0.001719521, 0.003097193, -0.015995396, 0.056165468, 0.016530346, 0.02278677, -0.011639266, 0.033604246, -0.005484241, -0.008179427, 0.006437233, 0.009859413, 0.0058089322, -0.003004451, -0.031272896, 0.01951176, -0.02244156, -0.0007966452, -0.014868322, -0.013613085, -0.046897493, -0.009464215, -0.004882751, 0.067080334, -0.00967406, -0.05804073, -0.04735992, -0.042828742, 0.041059714, 0.030207371, 0.008116663, -0.03271577, 0.040146895, -0.0046853395, 0.08978497, 0.03983929, 0.031601556, -0.012560153, -0.07478509, 0.036060534, -0.02661313, -0.052547265, 0.06006379, 0.020274777, 0.05962854, 0.037343368, 0.00016860022, -0.05548778, 0.0058245244, -0.024818242, 0.048478298, -0.045036588, -0.06077684, 0.027391678, -0.024977801, -0.0130811855, -0.013756657, 0.037051074, 0.0020198284, -0.015468537, 0.034008693, -0.012375112, -0.026629096, -0.024138525, -0.0028480745, 0.022095049, 0.028037572, -0.0022509508, -0.07749398, 0.005022982, -0.00727295, -0.0068259165, 0.033115737, 0.0199505, 0.02114185, -0.02685578, -0.0018063094, -0.028142417, 0.032107648, -0.0051912, -0.017426535, -0.02652257, 0.050899137, 0.07368626, -0.05223529, 0.017580785, -0.037041664, 0.044566315, 0.018671582, -0.037815716, 0.011987722, 0.045169678, 0.0018121509, -0.054195236, 0.040377054, -0.03560927, 0.028140383, -0.05785241, 0.0224414, -0.01723669, 0.0561466, -0.055736516, 0.05304633, -0.022575628, 0.0052431994, -0.0042948127, 0.02436946, 0.0022056433, -0.01979279, 0.015822545, -0.008147554, -0.07423585, -0.03339149, 0.013066235, -0.01187028, -0.020151962, -0.06850732, -0.008372619, 0.024413073, 0.020091904, 0.020336445, 0.012789065, -0.06764696, -0.045821164, -0.0055136047, 0.0047791307, 0.0031694137, 0.02522163, -0.04401261, 0.012363201, -0.037120275, 0.0008360032, 0.011992481, -0.043828662, 0.026020128, 0.0042924234, -0.011801815, 0.013763202, -0.028328393, -0.023023061, 0.0053759757, 0.0082407, -0.00683523, -0.03910741, -0.011131156, -0.04065926, 0.062105477, -0.030005787, 0.008815181, -0.0068519283, 0.02996907, 0.046584453, -0.005073496, -0.0556667, 0.02273535, 0.049004138, -0.071780995, -0.017514545, 0.035166133, -0.03701806, 0.027807051, 0.0067200083, 0.01502184, -0.07308113, -0.01565129, 0.006448082, 0.0033324594, -0.07387746, -0.034777664, -0.025501003, -0.057104725, -0.055287365, -0.048452098, 0.024113743, 0.04658167, -0.022405125, -0.06267569, -0.004570461, -0.059221018, 0.052694935, -0.018907353, 0.052803356, 0.009114983, 0.008847871, 0.017884597, -0.012461748, 0.007115059, 0.06514109, 0.03851582, 0.0010109595, -0.02679693, 0.0440594, 0.033150308, -0.03787282, 0.045454856, 0.018557783, 0.04423571, 0.009434926, -0.018786436, 0.011439567, -0.010121315, -0.013313844, -0.079615265, -0.06944216, 0.028278736, -0.0075909663, -0.02463477, -0.039142255, 0.00896758, -0.062434103, 0.020346908, 0.00041840403, 0.0032588828, 0.0013163894, 0.0139276525, -0.059302736, 0.0017989055, 0.0050368253, -0.036957737, 0.05609387, 0.027446913, 0.048582558, 0.00085496495, 0.026958888, 0.044498097, 0.07772627, 0.008387499, -0.0303049, -0.059627995, -0.054744348, 0.00859041, -0.0057558618, -0.034558408, -0.06779239, -0.038804088, -0.022811249, -0.003363676, -0.03402216, -0.041637838, -0.00330985, -0.0028770245, -0.04236713, -0.03326566, 0.04482313, 0.019490544, -0.0040578675, 0.016802287, -0.0039889435, 0.021772845, -0.043549962, 0.020313663, 0.03430936, -0.023447376, -0.02066283, 0.039019875, -0.016220504, -0.04215773, 0.021813728, -0.065994024, 0.07613311, 0.011731492, -0.008362567, 0.00012437502, 0.033292428, 0.06682148, -0.013518166, -0.1006325, -0.04644204, -0.01334807, 0.076750234, 0.018476246, -0.0517865, 0.07000404, 0.022649882, 0.022437468, 0.032241434, 0.008218156, 0.0071493867, -0.013493118, -0.01979121, -0.029615989, -0.0347772, -0.0017923745, -0.025104601, 0.008120665, 0.047571316, 0.03767663, 0.050216496, -0.029191645, -0.03281201, -0.0031025563, -0.034206156, 0.008791988, -0.016895216, -0.006913128, -0.04897359, 0.017669087, 0.0008898749, -0.047825992, 0.034203783, -0.045691345, 0.0274288, 0.08153559, 0.038468108, 0.0029880963, -0.02187591, 0.025951318, -0.015224254, -0.051080674, 0.0028201214, -0.011769741, -0.0447073], 'text': 'Dieses Dokument dient als umfassende Wissensbasis f√ºr den LebensmittelBeratungsassistenten. Es enth√§lt detaillierte Informationen zu verschiedenen Di√§ten, Ern√§hrungspl√§nen und gesunden Lebensgewohnheiten. Der Assistent nutzt diese Informationen, um pr√§zise und individuell zugeschnittene Empfehlungen zu geben. Ziel ist es, Nutzern zu helfen, fundierte Entscheidungen bei der Auswahl von Di√§ten oder Ern√§hrungsstrategien zu treffen und ihre gesundheitlichen Ziele effektiv zu unterst√ºtzen.\\nDie Daten in diesem Dokument umfassen Di√§toptionen, spezifische Kontraindikationen, h√§ufig gestellte Fragen und Beispiel-Tagespl√§ne, die von der RAG-Pipeline verarbeitet und genutzt werden, um personalisierte Beratung zu bieten. Die Informationen werden kontinuierlich √ºberpr√ºft und aktualisiert, um sicherzustellen, dass sie die neuesten wissenschaftlichen Erkenntnisse und praktischen Ans√§tze widerspiegeln.', 'headings': '3.1 Zweck des Dokuments', 'page_info': ''}\n"
     ]
    }
   ],
   "source": [
    "prepared_embeddings = my_embedder.get_prepared_data_for_indexing(chunker_result)\n",
    "print(prepared_embeddings[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f23e228",
   "metadata": {},
   "source": [
    "### Vektor-DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fdc4dd00",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VectorDBCreator:\n",
    "    def __init__(self, milvus_client_name):\n",
    "        self.milvus_client = MilvusClient(f\"{milvus_client_name}.db\")\n",
    "\n",
    "    def create_collection(self, collection_name: str, dimension: int, **kwargs):\n",
    "        if self.milvus_client.has_collection(collection_name=collection_name):\n",
    "            self.milvus_client.drop_collection(collection_name=collection_name)\n",
    "        self.milvus_client.create_collection(\n",
    "            collection_name=collection_name,\n",
    "            dimension=dimension,\n",
    "            primary_field_name='id',\n",
    "            id_type=DataType.INT64,\n",
    "            vector_field_name='vector',\n",
    "            extra_fields=[\n",
    "                {\"name\": \"text\", \"type\": DataType.VARCHAR, \"max_length\": 1024},\n",
    "                {\"name\": \"headings\", \"type\": DataType.VARCHAR, \"max_length\": 512},\n",
    "                {\"name\": \"page_info\", \"type\": DataType.VARCHAR, \"max_length\": 128}\n",
    "            ],\n",
    "            metric_type='IP',\n",
    "            auto_id=True,\n",
    "            consistency_level='Strong',\n",
    "            **kwargs\n",
    "        )\n",
    "        print(f\"Collection '{collection_name}' with dimension {dimension} created.\")\n",
    "    \n",
    "    def get_milvus_client(self):\n",
    "        return self.milvus_client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d7a27ab9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collection 'my_collection' with dimension 768 created.\n"
     ]
    }
   ],
   "source": [
    "my_vdb_creator = VectorDBCreator(\"my_vector_db_01\")\n",
    "my_vdb_creator.create_collection(\"my_collection\", dimension=768)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d540069",
   "metadata": {},
   "source": [
    "### Indexing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2840f10f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DocumentIndexer:\n",
    "    def __init__(self, milvus_client, collection_name: str):\n",
    "        self.milvus_client = milvus_client\n",
    "        self.collection_name = collection_name\n",
    "\n",
    "    def index(self, data: list) -> dict:\n",
    "        print(f\"Inserting {len(data)} vectors into collection '{self.collection_name}'...\")\n",
    "        self.milvus_client.insert(collection_name=self.collection_name, data=data)\n",
    "        stats = {\"indexed_count\": len(data)}\n",
    "        print(f\"Finished indexing: {stats['indexed_count']} vectors inserted.\")\n",
    "        return stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b09e5110",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inserting 98 vectors into collection 'my_collection'...\n",
      "Finished indexing: 98 vectors inserted.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'indexed_count': 98}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_document_indexer = DocumentIndexer(my_vdb_creator.get_milvus_client(), \"my_collection\")\n",
    "my_document_indexer.index(prepared_embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4042cced",
   "metadata": {},
   "source": [
    "### Retrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "53aa0c00",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DocumentRetriever:\n",
    "    def __init__(self, milvus_client, collection_name: str, embedder):\n",
    "        self.milvus_client = milvus_client\n",
    "        self.collection_name = collection_name\n",
    "        self.embedder = embedder\n",
    "\n",
    "    def retrieve(self, query: str, k: int = 5) -> list:\n",
    "        print(f\"Processing query: {query}\")\n",
    "        query_embedding = self.embedder.get_embeddings(query)\n",
    "        search_results = self.milvus_client.search(\n",
    "            collection_name=self.collection_name,\n",
    "            data=[query_embedding],\n",
    "            limit=k,\n",
    "            search_params={\"metric_type\": \"IP\", \"params\": {}},\n",
    "            output_fields=[\"text\", \"headings\", \"page_info\"]\n",
    "        )\n",
    "        results = []\n",
    "        for res in search_results[0]:\n",
    "            entity = res[\"entity\"]\n",
    "            results.append({\n",
    "                \"text\": entity.get(\"text\", \"\"),\n",
    "                \"headings\": entity.get(\"headings\", []),\n",
    "                \"page_info\": entity.get(\"page_info\", None),\n",
    "                \"distance\": res[\"distance\"]\n",
    "            })\n",
    "        return results\n",
    "\n",
    "    def format_context(self, chunks: list) -> str:\n",
    "        context_parts = []\n",
    "        for i, chunk in enumerate(chunks):\n",
    "            headings_field = chunk.get(\"headings\", None)\n",
    "            if isinstance(headings_field, list):\n",
    "                heading_path = \" > \".join(headings_field) if headings_field else \"Document section\"\n",
    "            elif isinstance(headings_field, str):\n",
    "                heading_path = headings_field or \"Document section\"\n",
    "            else:\n",
    "                heading_path = \"Document section\"\n",
    "                \n",
    "            page_ref = f\"(Page {chunk.get('page_info')})\" if chunk.get('page_info') else \"\"\n",
    "            context_parts.append(\n",
    "                f\"EXCERPT {i+1} - {heading_path} {page_ref}:\\n{chunk['text']}\\n\"\n",
    "            )\n",
    "        return \"\\n\".join(context_parts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "aa3b0448",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing query: Wie viele Kalorien brauche ich bei wenig Bewegung?\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "```json\n",
       "[\n",
       "  {\n",
       "    \"text\": \"Um deinen Kalorienbedarf zu berechnen, musst du deinen Grundumsatz (BMR) und deinen Aktivit\\u00e4tsfaktor kennen. Der BMR gibt an, wie viele Kalorien du im Ruhezustand verbrauchst, und der Aktivit\\u00e4tsfaktor ber\\u00fccksichtigt deine t\\u00e4glichen Aktivit\\u00e4ten.\",\n",
       "    \"headings\": \"8.3 Wie berechne ich meinen Kalorienbedarf?\",\n",
       "    \"page_info\": \"\",\n",
       "    \"distance\": 0.6846004724502563\n",
       "  },\n",
       "  {\n",
       "    \"text\": \"Der Kalorienbedarf eines Menschen h\\u00e4ngt von verschiedenen Faktoren ab, wie Alter, Geschlecht, Gewicht, Gr\\u00f6\\u00dfe und Aktivit\\u00e4tsniveau. Der Grundumsatz (BMR) ist die Anzahl der Kalorien, die der K\\u00f6rper in Ruhe ben\\u00f6tigt, um lebenswichtige Funktionen aufrechtzuerhalten. Der Gesamtenergieumsatz (TDEE) ber\\u00fccksichtigt zus\\u00e4tzlich die k\\u00f6rperliche Aktivit\\u00e4t.\",\n",
       "    \"headings\": \"5.1 Kalorienbedarf\",\n",
       "    \"page_info\": \"\",\n",
       "    \"distance\": 0.6833980083465576\n",
       "  },\n",
       "  {\n",
       "    \"text\": \"- \\u00b7 Kalorien insgesamt: 1.700 kcal\",\n",
       "    \"headings\": \"7.1.5 Gesamtkalorien und Makron\\u00e4hrstoffe\",\n",
       "    \"page_info\": \"\",\n",
       "    \"distance\": 0.6613255739212036\n",
       "  }\n",
       "]\n",
       "```"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "my_document_retriever = DocumentRetriever(my_vdb_creator.get_milvus_client(), \"my_collection\", my_embedder)\n",
    "\n",
    "retriever_results = my_document_retriever.retrieve(\"Wie viele Kalorien brauche ich bei wenig Bewegung?\", k=3)\n",
    "show_pretty_json(retriever_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7146ed1e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">EXCERPT <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span> - <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">8.3</span> Wie berechne ich meinen Kalorienbedarf? :\n",
       "Um deinen Kalorienbedarf zu berechnen, musst du deinen Grundumsatz <span style=\"font-weight: bold\">(</span>BMR<span style=\"font-weight: bold\">)</span> und deinen Aktivit√§tsfaktor kennen. Der \n",
       "BMR gibt an, wie viele Kalorien du im Ruhezustand verbrauchst, und der Aktivit√§tsfaktor ber√ºcksichtigt deine \n",
       "t√§glichen Aktivit√§ten.\n",
       "\n",
       "EXCERPT <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span> - <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5.1</span> Kalorienbedarf :\n",
       "Der Kalorienbedarf eines Menschen h√§ngt von verschiedenen Faktoren ab, wie Alter, Geschlecht, Gewicht, Gr√∂√üe und \n",
       "Aktivit√§tsniveau. Der Grundumsatz <span style=\"font-weight: bold\">(</span>BMR<span style=\"font-weight: bold\">)</span> ist die Anzahl der Kalorien, die der K√∂rper in Ruhe ben√∂tigt, um \n",
       "lebenswichtige Funktionen aufrechtzuerhalten. Der Gesamtenergieumsatz <span style=\"font-weight: bold\">(</span>TDEE<span style=\"font-weight: bold\">)</span> ber√ºcksichtigt zus√§tzlich die \n",
       "k√∂rperliche Aktivit√§t.\n",
       "\n",
       "EXCERPT <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span> - <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">7.1</span>.<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5</span> Gesamtkalorien und Makron√§hrstoffe :\n",
       "- ¬∑ Kalorien insgesamt: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1.700</span> kcal\n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "EXCERPT \u001b[1;36m1\u001b[0m - \u001b[1;36m8.3\u001b[0m Wie berechne ich meinen Kalorienbedarf? :\n",
       "Um deinen Kalorienbedarf zu berechnen, musst du deinen Grundumsatz \u001b[1m(\u001b[0mBMR\u001b[1m)\u001b[0m und deinen Aktivit√§tsfaktor kennen. Der \n",
       "BMR gibt an, wie viele Kalorien du im Ruhezustand verbrauchst, und der Aktivit√§tsfaktor ber√ºcksichtigt deine \n",
       "t√§glichen Aktivit√§ten.\n",
       "\n",
       "EXCERPT \u001b[1;36m2\u001b[0m - \u001b[1;36m5.1\u001b[0m Kalorienbedarf :\n",
       "Der Kalorienbedarf eines Menschen h√§ngt von verschiedenen Faktoren ab, wie Alter, Geschlecht, Gewicht, Gr√∂√üe und \n",
       "Aktivit√§tsniveau. Der Grundumsatz \u001b[1m(\u001b[0mBMR\u001b[1m)\u001b[0m ist die Anzahl der Kalorien, die der K√∂rper in Ruhe ben√∂tigt, um \n",
       "lebenswichtige Funktionen aufrechtzuerhalten. Der Gesamtenergieumsatz \u001b[1m(\u001b[0mTDEE\u001b[1m)\u001b[0m ber√ºcksichtigt zus√§tzlich die \n",
       "k√∂rperliche Aktivit√§t.\n",
       "\n",
       "EXCERPT \u001b[1;36m3\u001b[0m - \u001b[1;36m7.1\u001b[0m.\u001b[1;36m5\u001b[0m Gesamtkalorien und Makron√§hrstoffe :\n",
       "- ¬∑ Kalorien insgesamt: \u001b[1;36m1.700\u001b[0m kcal\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "formatted_context = my_document_retriever.format_context(retriever_results)\n",
    "rprint(formatted_context)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab001e11",
   "metadata": {},
   "source": [
    "## Agent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30d94d54",
   "metadata": {},
   "source": [
    "### Agent-Tool f√ºr RAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfdd7e00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----- Extrahierte Daten -----\n",
      "{\n",
      "    \"age\": 20,\n",
      "    \"gender\": \"m√§nnlich\",\n",
      "    \"weight\": 85.0,\n",
      "    \"height\": 1.8,\n",
      "    \"allergies\": \"Laktoseintoleranz\",\n",
      "    \"eating_habits\": \"Vegan\",\n",
      "    \"goal\": \"Muskelaufbau durch Sport\",\n",
      "    \"activity_level\": \"moderat\",\n",
      "    \"timeCooking\": 120,\n",
      "    \"healthCondition\": \"Diabetes\"\n",
      "}\n",
      "ANSWER:\n",
      "I apologize for the mistake in my previous response. Based on your input, I will recalculate the calorie needs.\n",
      "\n",
      "To determine your daily calorie needs, we need to consider your activity level, age, weight, and height. As a moderately active 20-year-old male who is 85 kg and 1.8 meters tall, your basal metabolic rate (BMR) can be estimated as follows:\n",
      "\n",
      "BMR = 66 + (6.2 x weight in kg) + (12.7 x height in cm) - (6.8 x age in years)\n",
      "= 66 + (6.2 x 85) + (12.7 x 180) - (6.8 x 20)\n",
      "= 66 + 526 + 2280 - 136\n",
      "= 2454 calories\n",
      "\n",
      "Since you are moderately active, your daily calorie needs will be higher than your BMR. A commonly used estimate for daily calorie needs is the Harris-Benedict equation, which multiplies the BMR by an activity factor:\n",
      "\n",
      "Daily calorie needs = BMR x activity factor\n",
      "= 2454 x 1.55 (moderate activity)\n",
      "= approximately 3810 calories\n",
      "\n",
      "However, as you are following a vegan diet and have diabetes, your calorie needs may be different. A more accurate estimate would require considering the specific nutritional requirements of your diet.\n",
      "\n",
      "In general, a vegan diet can be high in fiber and low in certain nutrients like vitamin B12 and omega-3 fatty acids. As someone with diabetes, it's essential to monitor your carbohydrate intake and ensure you're getting enough protein and healthy fats.\n",
      "\n",
      "To achieve your goal of building muscle through sport, you'll need to consume more calories than your daily needs. A safe estimate for muscle gain is an additional 250-500 calories above your daily calorie needs.\n",
      "\n",
      "Therefore, I recommend the following daily calorie intake:\n",
      "\n",
      "* Basal calorie needs: approximately 3810 calories\n",
      "* Additional calories for muscle gain: 375 (midpoint of 250-500)\n",
      "* Total daily calorie needs: approximately 4185 calories\n",
      "\n",
      "Please note that this is an estimate and may vary depending on your individual circumstances. It's always best to consult with a registered dietitian or healthcare professional for personalized nutrition advice.\n",
      "\n",
      "Also, considering your lactose intolerance, I recommend choosing vegan-friendly protein sources like legumes, beans, lentils, tofu, tempeh, and seitan. Additionally, ensure you're getting enough calcium from plant-based sources like fortified plant milk, dark leafy greens, and tofu.\n",
      "\n",
      "Lastly, with diabetes, it's crucial to monitor your blood sugar levels regularly and adjust your carbohydrate intake accordingly. Consult with your healthcare provider or registered dietitian for personalized guidance on managing your condition through nutrition.\n",
      "\n",
      "I hope this information helps you in your fitness journey!\n",
      "\n",
      "== DETAILED AGENT RUN TRACE ==\n",
      "\n",
      "Total items generated: 3\n",
      "Model responses: 2\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "[STEP 1: tool_call_item]\n",
      "  Agent: Food Advisory Assistant\n",
      "  Tool called: calorie_calculator\n",
      "  Arguments: {\"activity_level\":\"moderat\",\"age\":20,\"gender\":\"m√§nnlich\",\"height_cm\":1.8,\"weight_kg\":85}\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "[STEP 2: tool_call_output_item]\n",
      "  Agent: Food Advisory Assistant\n",
      "  Output type: function_call_output\n",
      "  Output: An error occurred while running the tool. Please try again. Error: Invalid gender. Use 'm' for male or 'f' for female.\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "[STEP 3: message_output_item]\n",
      "  Agent: Food Advisory Assistant\n",
      "  Role: assistant\n",
      "  Content: I apologize for the mistake in my previous response. Based on your input, I will recalculate the calorie needs.\n",
      "\n",
      "To determine your daily calorie needs...\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "== TOKEN USAGE ==\n",
      "Response 1:\n",
      "  Input tokens: 684\n",
      "  Output tokens: 55\n",
      "  Total tokens: 739\n",
      "Response 2:\n",
      "  Input tokens: 380\n",
      "  Output tokens: 569\n",
      "  Total tokens: 949\n",
      "\n",
      "Total input tokens: 1064\n",
      "Total output tokens: 624\n",
      "Grand total tokens: 1688\n",
      "\n",
      "== RETRIEVED CONTEXT ==\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'success'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Configuration\n",
    "class Config:\n",
    "    OLLAPI_ENDPOINT_BASE = 'http://localhost:11434/v1'  # Base endpoint for Ollama\n",
    "    OMODEL_LLAMA3D2 = 'llama3.2:latest'  # Model name\n",
    "\n",
    "# Context class for agent state\n",
    "class RAGContext(BaseModel):\n",
    "    question: str = \"\"\n",
    "    formatted_context: str = \"\"\n",
    "    language: str = \"English\"  # Default language for responses\n",
    "\n",
    "# Initialize the model - separate function for clarity\n",
    "def create_llm_model():\n",
    "    # Disable tracing to avoid messages about missing API keys\n",
    "    set_tracing_disabled(True)\n",
    "    \n",
    "    # Create model with your endpoint\n",
    "    return OpenAIChatCompletionsModel(\n",
    "        model=config.OMODEL_LLAMA3D2,\n",
    "        openai_client=AsyncOpenAI(\n",
    "            base_url=config.OLLAPI_ENDPOINT_BASE, \n",
    "            api_key=\"fake-key\"  # Using fake key as local endpoint doesn't require auth\n",
    "        )\n",
    "    )\n",
    "\n",
    "# Function to extract information from prompt\n",
    "async def extract_health_info(prompt: str) -> HealthData:\n",
    "    data = {\n",
    "        \"model\": config.OMODEL_LLAMA3D2,\n",
    "        \"prompt\": prompt + \"\\nAntworte in JSON, passend zum Schema der HealthData-Klasse.\",\n",
    "        \"stream\": False,\n",
    "        \"format\": HealthData.model_json_schema()\n",
    "    }\n",
    "    response = requests.post(config.OAPI_GENERATE_URL, json=data)\n",
    "    response_json = response.json()\n",
    "    response_data = json.loads(response_json[\"response\"])\n",
    "    return HealthData(**response_data)\n",
    "\n",
    "# Diet comparison tool that uses DocumentRetriever\n",
    "@function_tool\n",
    "async def diet_comparison(\n",
    "    context: RunContextWrapper[RAGContext], \n",
    "    query: str, \n",
    "    k: int = 4\n",
    "    ) -> str:\n",
    "    \"\"\"\n",
    "    Compares retrieved information about various diets.\n",
    "    \"\"\"\n",
    "\n",
    "    try:\n",
    "        # Store the question in context\n",
    "        context.context.question = query\n",
    "        \n",
    "        # Use your existing document retriever\n",
    "        retriever_results = my_document_retriever.retrieve(query, k=k)\n",
    "        formatted_context = my_document_retriever.format_context(retriever_results)\n",
    "        \n",
    "        # Store formatted context in the agent context\n",
    "        context.context.formatted_context = formatted_context\n",
    "        \n",
    "        return formatted_context\n",
    "    except Exception as e:\n",
    "        error_msg = f\"Error retrieving documents: {str(e)}\"\n",
    "        print(error_msg)\n",
    "        return error_msg\n",
    "    \n",
    "# BMI calculator\n",
    "@function_tool\n",
    "def bmi_calculator(height, weight) -> str:\n",
    "    \"\"\"\n",
    "    Calculates the Body Mass Index (BMI) with given parameters.\n",
    "\n",
    "    :param height: height in meters\n",
    "    :param weight: weight in kilograms \n",
    "    :return: BMI\n",
    "    \"\"\"\n",
    "    \n",
    "    response = weight / float(height * height)\n",
    "    response.raise_for_status()  # Ensure we catch any HTTP errors\n",
    "    return response\n",
    "    \n",
    "# Calorie calculator\n",
    "@function_tool\n",
    "async def calorie_calculator(gender: str, weight_kg: float, height_cm: float, age: int, activity_level: str) -> dict:\n",
    "    \"\"\"\n",
    "    Calculates Basal Metabolic Rate (BMR) and Total Daily Energy Expenditure (TDEE)\n",
    "    using the Mifflin-St. Jeor equation.\n",
    "\n",
    "    :param gender: \"m\" for male or \"f\" for female\n",
    "    :param weight_kg: Weight in kilograms\n",
    "    :param height_cm: Height in centimeters\n",
    "    :param age: Age in years\n",
    "    :param activity_level: One of the keys from `activity_factors`\n",
    "    :return: Dictionary with BMR, TDEE, and activity factor used\n",
    "    \"\"\"\n",
    "    activity_factors = {\n",
    "        \"sedentary\": 1.2,        # little or no exercise\n",
    "        \"light\": 1.375,          # light exercise 1‚Äì3 days/week\n",
    "        \"moderate\": 1.55,        # moderate exercise 3‚Äì5 days/week\n",
    "        \"active\": 1.725,         # hard exercise 6‚Äì7 days/week\n",
    "        \"very active\": 1.9       # very intense physical job or training\n",
    "    }\n",
    "\n",
    "    gender = gender.lower()\n",
    "    if gender == \"m\" or \"male\" or \"man\" or \"mann\" or \"m√§nnlich\":\n",
    "        bmr = 10 * weight_kg + 6.25 * height_cm - 5 * age + 5\n",
    "    elif gender == \"f\" or \"female\" or \"woman\" or \"frau\" or \"weiblich\":\n",
    "        bmr = 10 * weight_kg + 6.25 * height_cm - 5 * age - 161\n",
    "    else:\n",
    "        raise ValueError(\"Invalid gender. Use 'm' for male or 'f' for female.\")\n",
    "\n",
    "    factor = activity_factors.get(activity_level.lower())\n",
    "    if factor is None:\n",
    "        raise ValueError(f\"Invalid activity level: {activity_level}\")\n",
    "\n",
    "    tdee = bmr * factor\n",
    "\n",
    "    return {\n",
    "        \"BMR\": round(bmr, 2),\n",
    "        \"TDEE\": round(tdee, 2),\n",
    "        \"Activity Factor\": factor\n",
    "    }\n",
    "\n",
    "# Allergy information tool\n",
    "@function_tool\n",
    "async def allergy_check(\n",
    "    context: RunContextWrapper[RAGContext], \n",
    "    query: str, \n",
    "    k: int = 4\n",
    "    ) -> str:\n",
    "    \"\"\"\n",
    "    Retrieves information about potential allergies in diets.\n",
    "    \"\"\"\n",
    "\n",
    "    try:\n",
    "        # Store the question in context\n",
    "        context.context.question = query\n",
    "        \n",
    "        # Use your existing document retriever\n",
    "        retriever_results = my_document_retriever.retrieve(query, k=k)\n",
    "        formatted_context = my_document_retriever.format_context(retriever_results)\n",
    "        \n",
    "        # Store formatted context in the agent context\n",
    "        context.context.formatted_context = formatted_context\n",
    "        \n",
    "        return formatted_context\n",
    "    except Exception as e:\n",
    "        error_msg = f\"Error retrieving documents: {str(e)}\"\n",
    "        print(error_msg)\n",
    "        return error_msg\n",
    "\n",
    "# Create a single RAG agent - simplifying the design\n",
    "# Using valid tool_use_behavior value\n",
    "rag_agent = Agent[RAGContext](\n",
    "    name=\"Food Advisory Assistant\",\n",
    "    instructions=\"\"\"\n",
    "    You are an assistant specialized in dietary advice and health information.\n",
    "    \n",
    "    WORKFLOW:\n",
    "    1. When a user asks a question regarding diets, use the diet_comparison tool to retrieve relevant information\n",
    "    2. When a user asks a question regarding BMI, use the bmi_calculator tool to retrieve relevant information\n",
    "    3. When a user asks a question regarding calories, use the calorie_calculator tool to retrieve relevant information\n",
    "    4. When a user asks a question regarding allergies, use the allergy_check tool to retrieve relevant information\n",
    "    5. Carefully analyze the retrieved context\n",
    "    6. Provide a clear, accurate answer based on the retrieved information\n",
    "    7. If the information isn't available in the retrieved context, indicate this clearly\n",
    "    \n",
    "    Respond in English.\n",
    "    Be helpful, accurate, and concise in your responses.\n",
    "    \"\"\",\n",
    "    tools=[diet_comparison, bmi_calculator, allergy_check, calorie_calculator],\n",
    "    model=create_llm_model(),\n",
    "    # Using a valid tool_use_behavior value\n",
    "    tool_use_behavior=\"run_llm_again\",\n",
    "    # Set model settings to help with function calling\n",
    "    model_settings=ModelSettings(\n",
    "        temperature=0.1,  # Lower temperature for more deterministic responses\n",
    "        tool_choice=\"auto\"  # Auto tool choice\n",
    "    )\n",
    ")\n",
    "\n",
    "# Manual process for RAG when the model doesn't handle function calling properly\n",
    "async def manual_rag_process(question, k=1):\n",
    "    \"\"\"\n",
    "    Manually execute the RAG process when the model doesn't properly use function calling.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Direct call to retrieve documents\n",
    "        retriever_results = my_document_retriever.retrieve(question, k=k)\n",
    "        formatted_context = my_document_retriever.format_context(retriever_results)\n",
    "        \n",
    "        # Create a prompt with the retrieved context\n",
    "        formatted_prompt = f\"\"\"\n",
    "        Question: {question}\n",
    "\n",
    "        Context from diet plans:\n",
    "        {formatted_context}\n",
    "\n",
    "        Based on the above context, please provide a concise and accurate answer to the question.\n",
    "        \"\"\"\n",
    "        \n",
    "        # Create context with the retrieved info\n",
    "        context = RAGContext(\n",
    "            question=question,\n",
    "            formatted_context=formatted_context,\n",
    "            language=\"English\"\n",
    "        )\n",
    "        \n",
    "        # Use a list for input items with the formatted prompt\n",
    "        input_items = [{\"content\": formatted_prompt, \"role\": \"user\"}]\n",
    "        \n",
    "        # Run the model with this prompt\n",
    "        run_result = await Runner.run(\n",
    "            rag_agent,\n",
    "            input=input_items,\n",
    "            context=context\n",
    "        )\n",
    "        \n",
    "        # Return the results\n",
    "        return {\n",
    "            \"answer\": run_result.final_output,\n",
    "            \"run_result\": run_result,\n",
    "            \"context\": context\n",
    "        }\n",
    "    except Exception as e:\n",
    "        error_msg = f\"Error in manual RAG process: {str(e)}\"\n",
    "        print(error_msg)\n",
    "        return {\"error\": error_msg}\n",
    "\n",
    "# Detailed trace function for better visibility into the agent process\n",
    "def print_run_trace(run_result):\n",
    "    print(\"\\n== DETAILED AGENT RUN TRACE ==\\n\")\n",
    "    \n",
    "    # Print basic info\n",
    "    print(f\"Total items generated: {len(run_result.new_items)}\")\n",
    "    print(f\"Model responses: {len(run_result.raw_responses)}\")\n",
    "    print(\"-\" * 80)\n",
    "    \n",
    "    # Loop through each item and print details based on item type\n",
    "    for i, item in enumerate(run_result.new_items):\n",
    "        item_type = getattr(item, 'type', 'unknown')\n",
    "        \n",
    "        print(f\"\\n[STEP {i+1}: {item_type}]\")\n",
    "        \n",
    "        if item_type == 'tool_call_item':\n",
    "            # Print tool call details\n",
    "            print(f\"  Agent: {item.agent.name}\")\n",
    "            raw_item = item.raw_item\n",
    "            print(f\"  Tool called: {raw_item.name}\")\n",
    "            print(f\"  Arguments: {raw_item.arguments}\")\n",
    "            \n",
    "        elif item_type == 'tool_call_output_item':\n",
    "            # Print tool output details\n",
    "            print(f\"  Agent: {item.agent.name}\")\n",
    "            print(f\"  Output type: {item.raw_item.get('type', 'unknown')}\")\n",
    "            \n",
    "            # Truncate long outputs for readability\n",
    "            output = item.output\n",
    "            if len(output) > 150:\n",
    "                output = output[:150] + \"...\"\n",
    "            print(f\"  Output: {output}\")\n",
    "            \n",
    "        elif item_type == 'message_output_item':\n",
    "            # Print message details\n",
    "            print(f\"  Agent: {item.agent.name}\")\n",
    "            raw_item = item.raw_item\n",
    "            \n",
    "            # Extract and format content\n",
    "            content = \"\"\n",
    "            if hasattr(raw_item, 'content') and raw_item.content:\n",
    "                for content_item in raw_item.content:\n",
    "                    if hasattr(content_item, 'text'):\n",
    "                        text = content_item.text\n",
    "                        if len(text) > 150:\n",
    "                            text = text[:150] + \"...\"\n",
    "                        content = text\n",
    "            \n",
    "            print(f\"  Role: {getattr(raw_item, 'role', 'unknown')}\")\n",
    "            print(f\"  Content: {content}\")\n",
    "            \n",
    "        else:\n",
    "            # For any other item types\n",
    "            print(f\"  Item details: {item}\")\n",
    "            \n",
    "        print(\"-\" * 80)\n",
    "    \n",
    "    # Print token usage information if available\n",
    "    print(\"\\n== TOKEN USAGE ==\")\n",
    "    total_input_tokens = 0\n",
    "    total_output_tokens = 0\n",
    "    \n",
    "    for i, response in enumerate(run_result.raw_responses):\n",
    "        if hasattr(response, 'usage'):\n",
    "            usage = response.usage\n",
    "            input_tokens = getattr(usage, 'input_tokens', 0)\n",
    "            output_tokens = getattr(usage, 'output_tokens', 0)\n",
    "            total_tokens = getattr(usage, 'total_tokens', 0)\n",
    "            \n",
    "            print(f\"Response {i+1}:\")\n",
    "            print(f\"  Input tokens: {input_tokens}\")\n",
    "            print(f\"  Output tokens: {output_tokens}\")\n",
    "            print(f\"  Total tokens: {total_tokens}\")\n",
    "            \n",
    "            total_input_tokens += input_tokens\n",
    "            total_output_tokens += output_tokens\n",
    "    \n",
    "    print(f\"\\nTotal input tokens: {total_input_tokens}\")\n",
    "    print(f\"Total output tokens: {total_output_tokens}\")\n",
    "    print(f\"Grand total tokens: {total_input_tokens + total_output_tokens}\")\n",
    "\n",
    "# Main function with detection of function calling issues\n",
    "async def ask(\n",
    "    question: str, \n",
    "    document_retriever=None, \n",
    "    language=\"English\"\n",
    "    ) -> Dict:\n",
    "    # Allow passing a document retriever if not defined globally\n",
    "    global my_document_retriever\n",
    "    if document_retriever is not None:\n",
    "        my_document_retriever = document_retriever\n",
    "    \n",
    "    # Create context with specified language\n",
    "    context = RAGContext(language=language)\n",
    "    \n",
    "    # First attempt: standard approach\n",
    "    with trace(\"Food Advisory Assistant - Standard Approach\"):\n",
    "        # Format question to HealthData Object\n",
    "        formatted_question = await extract_health_info(question)\n",
    "        print(\"----- Extrahierte Daten -----\")\n",
    "        print(formatted_question.model_dump_json(indent=4))\n",
    "\n",
    "        # Use a list for input items\n",
    "        input_items = [{\"content\": str(formatted_question), \"role\": \"user\"}]\n",
    "        \n",
    "        # Run the agent\n",
    "        run_result = await Runner.run(\n",
    "            rag_agent,\n",
    "            input=input_items,\n",
    "            context=context\n",
    "        )\n",
    "    \n",
    "    # Check if we got a proper answer or just a function call spec\n",
    "    is_function_call_text = False\n",
    "    if run_result.final_output:\n",
    "        # Check if the output looks like a raw function call\n",
    "        if run_result.final_output.startswith('{\"name\":') or \\\n",
    "           'diet_comparison' in run_result.final_output:\n",
    "            print(\"INSIDE \")\n",
    "            is_function_call_text = True\n",
    "    \n",
    "    # If the model returned a function call as text, use manual RAG approach\n",
    "    if is_function_call_text:\n",
    "        print(\"Detected function call specification in output. Switching to manual RAG process...\")\n",
    "        return await manual_rag_process(str(formatted_question), k=1)\n",
    "    \n",
    "    # Standard approach worked fine\n",
    "    return {\n",
    "        \"answer\": run_result.final_output,\n",
    "        \"run_result\": run_result,\n",
    "        \"context\": context\n",
    "    }\n",
    "\n",
    "# Example usage\n",
    "async def demo_rag():\n",
    "    question1 = \"Was passt besser zu mir: Low Carb oder Mittelmeerdi√§t?\"\n",
    "    question2 = \"Ich bin 1,75m gro√ü und wiege 95kg - wie hoch ist mein BMI?\"\n",
    "    question3 = \"Wie viele Kalorien brauche ich bei wenig Bewegung? Ich bin eine Frau, bin 30 Jahre, 170 cm gro√ü, mit 65 Kilo.\"\n",
    "    question4 = \"Ich bin laktoseintolerant - welche Di√§ten schlie√üen Milchprodukte aus?\"\n",
    "    question5 = \"Kannst du mein Ziel 'fitter werden' klarer formulieren?\"\n",
    "    question6 = \"\"\"\n",
    "                I am 20 years old, male, weigh 85kg, and am 1.80m tall.\n",
    "                I am lactose intolerant and enjoy eating vegan.\n",
    "                My goal is to build more muscle, which is why I exercise moderately.\n",
    "                For daily cooking, I plan to spend a maximum of 2 hours (120 minutes).\n",
    "                Unfortunately, I am also diabetic, so I need to keep an eye on my blood sugar levels.\n",
    "                Which type of diet can you recommend for me?\"\"\"\n",
    "    question7 = \"\"\"\n",
    "                Ich bin 20 Jahre alt, m√§nnlich, wiege 85kg und bin 1,80m gro√ü. \n",
    "                Ich bin laktoseintolerant und esse gerne vegan. \n",
    "                Mein Ziel ist es, mehr Muskeln aufzubauen, weshalb ich moderat Sport betreibe. \n",
    "                F√ºr das t√§gliche Kochen plane ich maximal 2 Stunden (120 min) ein. \n",
    "                Leider bin ich auch Diabetiker, weshalb ich auch auf meinen Zuckerhaushalt achten muss. \n",
    "                Welche Di√§tform kannst du mir empfehlen?\"\"\"\n",
    "    \n",
    "    # question6 = \"Welche Di√§ten gibt es?\"\n",
    "    # question7 = \"Welche Di√§t empfiehlt sich, wenn ich abnehmen m√∂chte?\"\n",
    "    # question8 = \"Welche Di√§t is kalorienarm?\"\n",
    "    # question9 = \"Welche Di√§ten beinhalten m√∂glicherweise Allergien?\"\n",
    "    # question10 = \"Was sind Makron√§hrstoffe?\"\n",
    "    # question11 = \"Welche Vitamine brauche ich f√ºr was und woher bekomme ich diese?\"\n",
    "    # question12 = \"Welchen Tagesplan sollte ich bei der Paleo Di√§t einhalten?\"\n",
    "\n",
    "    result = await ask(question7, my_document_retriever)\n",
    "    \n",
    "    # Print the answer\n",
    "    print(\"ANSWER:\")\n",
    "    print(result[\"answer\"])\n",
    "    \n",
    "    # Use our detailed trace function\n",
    "    print_run_trace(result['run_result'])\n",
    "    \n",
    "    # Print context preview\n",
    "    context = result.get('context')\n",
    "    if context and hasattr(context, 'formatted_context'):\n",
    "        print(\"\\n== RETRIEVED CONTEXT ==\")\n",
    "        print(context.formatted_context)\n",
    "    \n",
    "    return 'success' #result\n",
    "\n",
    "# For Jupyter notebook execution\n",
    "await demo_rag()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (lebensmittel-beratungsassistent)",
   "language": "python",
   "name": "lebensmittel-beratungsassistent"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
