{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9ea0849c",
   "metadata": {},
   "source": [
    "### üõ†Ô∏è Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "541ebdc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "from aiworkshop_utils.standardlib_imports import os, json, base64, logging, Optional, List, Literal, pprint, glob, asyncio, datetime, date, time, timezone, ZoneInfo, uuid, dataclass\n",
    "from aiworkshop_utils.thirdparty_imports import AutoTokenizer, load_dotenv, requests, BaseModel, Field, pd, cosine_similarity, plt, np, DataType, MilvusClient, DDGS, rprint\n",
    "from aiworkshop_utils.custom_utils import show_pretty_json, encode_image\n",
    "from aiworkshop_utils.jupyter_imports import Markdown, HTML, JSON, display, widgets\n",
    "from aiworkshop_utils.openai_imports import OpenAI, Agent, Runner, InputGuardrail, GuardrailFunctionOutput, InputGuardrailTripwireTriggered, OpenAIChatCompletionsModel, AsyncOpenAI, set_tracing_disabled, ModelSettings, function_tool, trace, ResponseContentPartDoneEvent, ResponseTextDeltaEvent, RawResponsesStreamEvent, TResponseInputItem, ItemHelpers, MessageOutputItem, RunContextWrapper, input_guardrail, output_guardrail\n",
    "from aiworkshop_utils import config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dd4f916",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard library imports\n",
    "import os\n",
    "import json\n",
    "import base64\n",
    "import logging\n",
    "from typing import Optional, List, Dict, Any, Union, Literal\n",
    "import asyncio\n",
    "from datetime import datetime, date, time, timezone\n",
    "from zoneinfo import ZoneInfo\n",
    "import uuid\n",
    "from dataclasses import dataclass\n",
    "from pprint import pprint\n",
    "from glob import glob\n",
    "\n",
    "# Third-party imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import requests\n",
    "from dotenv import load_dotenv\n",
    "from pydantic import BaseModel, Field\n",
    "from rich import print as rprint\n",
    "from tqdm import tqdm\n",
    "from pymilvus import DataType, MilvusClient, Collection\n",
    "from duckduckgo_search import DDGS\n",
    "\n",
    "# Document processing imports\n",
    "from docling.backend.pypdfium2_backend import PyPdfiumDocumentBackend\n",
    "from docling.chunking import HybridChunker\n",
    "from docling.datamodel.base_models import InputFormat\n",
    "from docling.datamodel.pipeline_options import (\n",
    "    AcceleratorDevice,\n",
    "    AcceleratorOptions,\n",
    "    PdfPipelineOptions,\n",
    ")\n",
    "from docling.document_converter import (\n",
    "    DocumentConverter,\n",
    "    PdfFormatOption,\n",
    "    WordFormatOption,\n",
    ")\n",
    "from docling.pipeline.simple_pipeline import SimplePipeline\n",
    "\n",
    "# OpenAI and Agent imports\n",
    "from openai import OpenAI, AsyncOpenAI\n",
    "from agents import (\n",
    "    Agent,\n",
    "    GuardrailFunctionOutput,\n",
    "    InputGuardrail,\n",
    "    InputGuardrailTripwireTriggered,\n",
    "    ModelSettings,\n",
    "    OpenAIChatCompletionsModel,\n",
    "    Runner,\n",
    "    function_tool,\n",
    "    set_tracing_disabled,\n",
    "    trace,\n",
    "    RawResponsesStreamEvent,\n",
    "    ItemHelpers, \n",
    "    MessageOutputItem,\n",
    "    RunContextWrapper,\n",
    "    input_guardrail,\n",
    "    output_guardrail\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6415a181",
   "metadata": {},
   "source": [
    "### Pydantic Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff0cadbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class HealthData(BaseModel):\n",
    "    age: int = Field(description=\"Age in years\")\n",
    "    gender: str = Field(description=\"e.g. male, female, diverse\")\n",
    "    weight: float = Field(description=\"Weight in kg\")   \n",
    "    height: float = Field(description=\"Height in cm\")\n",
    "    allergies: Optional[str] = Field(description=\"e.g. nuts, gluten\")\n",
    "    eating_habits: str = Field(description=\"e.g. vegetarian, vegan, omnivore, paleo\")\n",
    "    goal: str = Field(description=\"e.g. weight loss, muscle gain, maintenance\")\n",
    "    activity_level: str = Field(description=\"e.g. sedentary, lightly active, moderately active, very active\")\n",
    "    timeCooking: int = Field(description=\"Time spent cooking per day in minutes\")\n",
    "    healthCondition: Optional[str] = Field(description=\"e.g. diabetes, hypertension\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "422a51ab",
   "metadata": {},
   "source": [
    "### Parsing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2200a71",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DocumentParser:\n",
    "    def __init__(self, converter):\n",
    "        self.converter = converter\n",
    "\n",
    "    def parse(self, file_path: str, options: dict = None):\n",
    "        print(f\"Converting document: {file_path}\")\n",
    "        result = self.converter.convert(file_path)\n",
    "        return result.document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91e8632f",
   "metadata": {},
   "outputs": [],
   "source": [
    "source = \"assets/health_data.pdf\"\n",
    "\n",
    "my_processor = DocumentParser(DocumentConverter())\n",
    "processor_result = my_processor.parse(source)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dcc51f1",
   "metadata": {},
   "source": [
    "### Chunking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4683989e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DocumentChunker:\n",
    "    def __init__(self, tokenizer: str = \"sentence-transformers/all-MiniLM-L6-v2\"):\n",
    "        self.tokenizer = tokenizer\n",
    "        self.chunker = HybridChunker(tokenizer=tokenizer)\n",
    "\n",
    "    def chunk(self, document, options: dict = None):\n",
    "        print(\"Chunking document...\")\n",
    "        chunks = list(self.chunker.chunk(document))\n",
    "        print(f\"Created {len(chunks)} chunks\")\n",
    "        return chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "961c6480",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_chunker = DocumentChunker()\n",
    "chunker_result = my_chunker.chunk(processor_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b1c9c99",
   "metadata": {},
   "source": [
    "### Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50bd09c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DocumentEmbedder:\n",
    "    def __init__(self, url, model_name):\n",
    "        self.url = url\n",
    "        self.model_name = model_name\n",
    "\n",
    "    def _post_request(self, texts):\n",
    "        if isinstance(texts, str):\n",
    "            texts = [texts]\n",
    "        response = requests.post(\n",
    "            self.url,\n",
    "            json={\n",
    "                \"model\": self.model_name,\n",
    "                \"input\": texts\n",
    "            }\n",
    "        )\n",
    "        response.raise_for_status()\n",
    "        return response.json()\n",
    "\n",
    "    def get_embeddings(self, texts):\n",
    "        response = self._post_request(texts)\n",
    "        embeddings = response[\"embeddings\"]\n",
    "        if isinstance(texts, str) or len(embeddings) == 1:\n",
    "            return embeddings[0]\n",
    "        return embeddings\n",
    "\n",
    "    def get_full_response(self, texts):\n",
    "        return self._post_request(texts)\n",
    "\n",
    "    def embed(self, chunks):\n",
    "        texts = [chunk.text for chunk in chunks]\n",
    "        return self.get_embeddings(texts)\n",
    "    \n",
    "    def get_prepared_data_for_indexing(self, chunks):\n",
    "        embedding_result = self.embed(chunks)\n",
    "        data = []\n",
    "        for chunk, vector in zip(chunks, embedding_result):\n",
    "            headings = \"\"\n",
    "            page_info = \"\"\n",
    "            if hasattr(chunk, \"meta\") and chunk.meta:\n",
    "                headings_list = getattr(chunk.meta, \"headings\", [])\n",
    "                if headings_list:\n",
    "                    headings = \" > \".join(headings_list)\n",
    "                page_info = getattr(chunk.meta, \"page_info\", \"\")\n",
    "            data.append({\n",
    "                \"vector\": vector,\n",
    "                \"text\": chunk.text,\n",
    "                \"headings\": headings,\n",
    "                \"page_info\": page_info\n",
    "            })\n",
    "        return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1b603cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_embedder = DocumentEmbedder(url=config.OAPI_EMBED_URL, model_name=config.OMODEL_NOMIC)\n",
    "embedding_result = my_embedder.embed(chunker_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "724c106f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(embedding_result))\n",
    "print(embedding_result[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeef7dce",
   "metadata": {},
   "outputs": [],
   "source": [
    "prepared_embeddings = my_embedder.get_prepared_data_for_indexing(chunker_result)\n",
    "print(prepared_embeddings[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9433274c",
   "metadata": {},
   "source": [
    "### Vektor-DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dd8ddd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VectorDBCreator:\n",
    "    def __init__(self, milvus_client_name):\n",
    "        self.milvus_client = MilvusClient(f\"{milvus_client_name}.db\")\n",
    "\n",
    "    def create_collection(self, collection_name: str, dimension: int, **kwargs):\n",
    "        if self.milvus_client.has_collection(collection_name=collection_name):\n",
    "            self.milvus_client.drop_collection(collection_name=collection_name)\n",
    "        self.milvus_client.create_collection(\n",
    "            collection_name=collection_name,\n",
    "            dimension=dimension,\n",
    "            primary_field_name='id',\n",
    "            id_type=DataType.INT64,\n",
    "            vector_field_name='vector',\n",
    "            extra_fields=[\n",
    "                {\"name\": \"text\", \"type\": DataType.VARCHAR, \"max_length\": 1024},\n",
    "                {\"name\": \"headings\", \"type\": DataType.VARCHAR, \"max_length\": 512},\n",
    "                {\"name\": \"page_info\", \"type\": DataType.VARCHAR, \"max_length\": 128}\n",
    "            ],\n",
    "            metric_type='IP',\n",
    "            auto_id=True,\n",
    "            consistency_level='Strong',\n",
    "            **kwargs\n",
    "        )\n",
    "        print(f\"Collection '{collection_name}' with dimension {dimension} created.\")\n",
    "    \n",
    "    def get_milvus_client(self):\n",
    "        return self.milvus_client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26d1571d",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_vdb_creator = VectorDBCreator(\"my_vector_db_01\")\n",
    "my_vdb_creator.create_collection(\"my_collection\", dimension=768)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e22679a3",
   "metadata": {},
   "source": [
    "### Indexing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c89841a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DocumentIndexer:\n",
    "    def __init__(self, milvus_client, collection_name: str):\n",
    "        self.milvus_client = milvus_client\n",
    "        self.collection_name = collection_name\n",
    "\n",
    "    def index(self, data: list) -> dict:\n",
    "        print(f\"Inserting {len(data)} vectors into collection '{self.collection_name}'...\")\n",
    "        self.milvus_client.insert(collection_name=self.collection_name, data=data)\n",
    "        stats = {\"indexed_count\": len(data)}\n",
    "        print(f\"Finished indexing: {stats['indexed_count']} vectors inserted.\")\n",
    "        return stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4ce0da3",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_document_indexer = DocumentIndexer(my_vdb_creator.get_milvus_client(), \"my_collection\")\n",
    "my_document_indexer.index(prepared_embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec463700",
   "metadata": {},
   "source": [
    "### Retrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b375843c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DocumentRetriever:\n",
    "    def __init__(self, milvus_client, collection_name: str, embedder):\n",
    "        self.milvus_client = milvus_client\n",
    "        self.collection_name = collection_name\n",
    "        self.embedder = embedder\n",
    "\n",
    "    def retrieve(self, query: str, k: int = 5) -> list:\n",
    "        print(f\"Processing query: {query}\")\n",
    "        query_embedding = self.embedder.get_embeddings(query)\n",
    "        search_results = self.milvus_client.search(\n",
    "            collection_name=self.collection_name,\n",
    "            data=[query_embedding],\n",
    "            limit=k,\n",
    "            search_params={\"metric_type\": \"IP\", \"params\": {}},\n",
    "            output_fields=[\"text\", \"headings\", \"page_info\"]\n",
    "        )\n",
    "        results = []\n",
    "        for res in search_results[0]:\n",
    "            entity = res[\"entity\"]\n",
    "            results.append({\n",
    "                \"text\": entity.get(\"text\", \"\"),\n",
    "                \"headings\": entity.get(\"headings\", []),\n",
    "                \"page_info\": entity.get(\"page_info\", None),\n",
    "                \"distance\": res[\"distance\"]\n",
    "            })\n",
    "        return results\n",
    "\n",
    "    def format_context(self, chunks: list) -> str:\n",
    "        context_parts = []\n",
    "        for i, chunk in enumerate(chunks):\n",
    "            headings_field = chunk.get(\"headings\", None)\n",
    "            if isinstance(headings_field, list):\n",
    "                heading_path = \" > \".join(headings_field) if headings_field else \"Document section\"\n",
    "            elif isinstance(headings_field, str):\n",
    "                heading_path = headings_field or \"Document section\"\n",
    "            else:\n",
    "                heading_path = \"Document section\"\n",
    "                \n",
    "            page_ref = f\"(Page {chunk.get('page_info')})\" if chunk.get('page_info') else \"\"\n",
    "            context_parts.append(\n",
    "                f\"EXCERPT {i+1} - {heading_path} {page_ref}:\\n{chunk['text']}\\n\"\n",
    "            )\n",
    "        return \"\\n\".join(context_parts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6b22361",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_document_retriever = DocumentRetriever(my_vdb_creator.get_milvus_client(), \"my_collection\", my_embedder)\n",
    "\n",
    "retriever_results = my_document_retriever.retrieve(\"Wie viele Kalorien brauche ich bei wenig Bewegung?\", k=3)\n",
    "show_pretty_json(retriever_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc8989e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "formatted_context = my_document_retriever.format_context(retriever_results)\n",
    "rprint(formatted_context)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2599a97",
   "metadata": {},
   "source": [
    "### Agent-Tool f√ºr RAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac978e8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "class Config:\n",
    "    OLLAPI_ENDPOINT_BASE = 'http://localhost:11434/v1'  # Base endpoint for Ollama\n",
    "    OMODEL_LLAMA3D2 = 'llama3.2:latest'  # Model name\n",
    "\n",
    "# Context class for agent state\n",
    "class RAGContext(BaseModel):\n",
    "    question: str = \"\"\n",
    "    formatted_context: str = \"\"\n",
    "    language: str = \"English\"  # Default language for responses\n",
    "\n",
    "# Initialize the model - separate function for clarity\n",
    "def create_llm_model():\n",
    "    # Disable tracing to avoid messages about missing API keys\n",
    "    set_tracing_disabled(True)\n",
    "    \n",
    "    # Create model with your endpoint\n",
    "    return OpenAIChatCompletionsModel(\n",
    "        model=config.OMODEL_LLAMA3D2,\n",
    "        openai_client=AsyncOpenAI(\n",
    "            base_url=config.OLLAPI_ENDPOINT_BASE, \n",
    "            api_key=\"fake-key\"  # Using fake key as local endpoint doesn't require auth\n",
    "        )\n",
    "    )\n",
    "\n",
    "# Diet comparison tool that uses DocumentRetriever\n",
    "@function_tool\n",
    "async def diet_comparison(\n",
    "    context: RunContextWrapper[RAGContext], \n",
    "    query: str, \n",
    "    k: int = 3\n",
    "    ) -> str:\n",
    "    try:\n",
    "        # Store the question in context\n",
    "        context.context.question = query\n",
    "        \n",
    "        # Use your existing document retriever\n",
    "        retriever_results = my_document_retriever.retrieve(query, k=k)\n",
    "        formatted_context = my_document_retriever.format_context(retriever_results)\n",
    "        \n",
    "        # Store formatted context in the agent context\n",
    "        context.context.formatted_context = formatted_context\n",
    "        \n",
    "        return formatted_context\n",
    "    except Exception as e:\n",
    "        error_msg = f\"Error retrieving documents: {str(e)}\"\n",
    "        print(error_msg)\n",
    "        return error_msg\n",
    "    \n",
    "class BMIData(BaseModel):\n",
    "    value: str\n",
    "    \n",
    "# BMI calculator\n",
    "@function_tool\n",
    "def bmi_calculator(height, weight) -> BMIData:\n",
    "    response = weight / float(height * height)\n",
    "    response.raise_for_status()  # Ensure we catch any HTTP errors\n",
    "    return response\n",
    "    \n",
    "# Calorie calculator\n",
    "@function_tool\n",
    "async def calorie_calculator(gender: str, weight_kg: float, height_cm: float, age: int, activity_level: str) -> dict:\n",
    "    \"\"\"\n",
    "    Calculates Basal Metabolic Rate (BMR) and Total Daily Energy Expenditure (TDEE)\n",
    "    using the Mifflin-St. Jeor equation.\n",
    "\n",
    "    :param gender: \"m\" for male or \"f\" for female\n",
    "    :param weight_kg: Weight in kilograms\n",
    "    :param height_cm: Height in centimeters\n",
    "    :param age: Age in years\n",
    "    :param activity_level: One of the keys from `activity_factors`\n",
    "    :return: Dictionary with BMR, TDEE, and activity factor used\n",
    "    \"\"\"\n",
    "    activity_factors = {\n",
    "        \"sedentary\": 1.2,        # little or no exercise\n",
    "        \"light\": 1.375,          # light exercise 1‚Äì3 days/week\n",
    "        \"moderate\": 1.55,        # moderate exercise 3‚Äì5 days/week\n",
    "        \"active\": 1.725,         # hard exercise 6‚Äì7 days/week\n",
    "        \"very active\": 1.9       # very intense physical job or training\n",
    "    }\n",
    "\n",
    "    gender = gender.lower()\n",
    "    if gender == \"m\":\n",
    "        bmr = 10 * weight_kg + 6.25 * height_cm - 5 * age + 5\n",
    "    elif gender == \"f\":\n",
    "        bmr = 10 * weight_kg + 6.25 * height_cm - 5 * age - 161\n",
    "    else:\n",
    "        raise ValueError(\"Invalid gender. Use 'm' for male or 'f' for female.\")\n",
    "\n",
    "    factor = activity_factors.get(activity_level.lower())\n",
    "    if factor is None:\n",
    "        raise ValueError(f\"Invalid activity level: {activity_level}\")\n",
    "\n",
    "    tdee = bmr * factor\n",
    "\n",
    "    return {\n",
    "        \"BMR\": round(bmr, 2),\n",
    "        \"TDEE\": round(tdee, 2),\n",
    "        \"Activity Factor\": factor\n",
    "    }\n",
    "\n",
    "\n",
    "    \n",
    "# Allergy information tool\n",
    "@function_tool\n",
    "async def allergy_check(\n",
    "    context: RunContextWrapper[RAGContext], \n",
    "    query: str, \n",
    "    k: int = 3\n",
    "    ) -> str:\n",
    "    try:\n",
    "        # Store the question in context\n",
    "        context.context.question = query\n",
    "        \n",
    "        # Use your existing document retriever\n",
    "        retriever_results = my_document_retriever.retrieve(query, k=k)\n",
    "        formatted_context = my_document_retriever.format_context(retriever_results)\n",
    "        \n",
    "        # Store formatted context in the agent context\n",
    "        context.context.formatted_context = formatted_context\n",
    "        \n",
    "        return formatted_context\n",
    "    except Exception as e:\n",
    "        error_msg = f\"Error retrieving documents: {str(e)}\"\n",
    "        print(error_msg)\n",
    "        return error_msg\n",
    "\n",
    "# Create a single RAG agent - simplifying the design\n",
    "# Using valid tool_use_behavior value\n",
    "rag_agent = Agent[RAGContext](\n",
    "    name=\"Food Advisory Assistant\",\n",
    "    instructions=\"\"\"\n",
    "    You are an assistant specialized in dietary advice and health information.\n",
    "    \n",
    "    WORKFLOW:\n",
    "    1. When a user asks a question regarding diets, use the diet_comparison tool to retrieve relevant information\n",
    "    2. When a user asks a question regarding BMI, use the bmi_calculator tool to retrieve relevant information\n",
    "    3. When a user asks a question regarding calories, use the calorie_calculator tool to retrieve relevant information\n",
    "    4. When a user asks a question regarding allergies, use the allergy_check tool to retrieve relevant information\n",
    "    5. Carefully analyze the retrieved context\n",
    "    6. Provide a clear, accurate answer based on the retrieved information\n",
    "    7. If the information isn't available in the retrieved context, indicate this clearly\n",
    "    \n",
    "    Respond in English.\n",
    "    Be helpful, accurate, and concise in your responses.\n",
    "    \"\"\",\n",
    "    tools=[diet_comparison, bmi_calculator, allergy_check, calorie_calculator],\n",
    "    model=create_llm_model(),\n",
    "    # Using a valid tool_use_behavior value\n",
    "    tool_use_behavior=\"run_llm_again\",\n",
    "    # Set model settings to help with function calling\n",
    "    model_settings=ModelSettings(\n",
    "        temperature=0.1,  # Lower temperature for more deterministic responses\n",
    "        tool_choice=\"auto\"  # Auto tool choice\n",
    "    )\n",
    ")\n",
    "\n",
    "# Manual process for RAG when the model doesn't handle function calling properly\n",
    "async def manual_rag_process(question, k=1):\n",
    "    \"\"\"\n",
    "    Manually execute the RAG process when the model doesn't properly use function calling.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Direct call to retrieve documents\n",
    "        retriever_results = my_document_retriever.retrieve(question, k=k)\n",
    "        formatted_context = my_document_retriever.format_context(retriever_results)\n",
    "        \n",
    "        # Create a prompt with the retrieved context\n",
    "        formatted_prompt = f\"\"\"\n",
    "        Question: {question}\n",
    "\n",
    "        Context from diet plans:\n",
    "        {formatted_context}\n",
    "\n",
    "        Based on the above context, please provide a concise and accurate answer to the question.\n",
    "        \"\"\"\n",
    "        \n",
    "        # Create context with the retrieved info\n",
    "        context = RAGContext(\n",
    "            question=question,\n",
    "            formatted_context=formatted_context,\n",
    "            language=\"English\"\n",
    "        )\n",
    "        \n",
    "        # Use a list for input items with the formatted prompt\n",
    "        input_items = [{\"content\": formatted_prompt, \"role\": \"user\"}]\n",
    "        \n",
    "        # Run the model with this prompt\n",
    "        run_result = await Runner.run(\n",
    "            rag_agent,\n",
    "            input=input_items,\n",
    "            context=context\n",
    "        )\n",
    "        \n",
    "        # Return the results\n",
    "        return {\n",
    "            \"answer\": run_result.final_output,\n",
    "            \"run_result\": run_result,\n",
    "            \"context\": context\n",
    "        }\n",
    "    except Exception as e:\n",
    "        error_msg = f\"Error in manual RAG process: {str(e)}\"\n",
    "        print(error_msg)\n",
    "        return {\"error\": error_msg}\n",
    "\n",
    "# Detailed trace function for better visibility into the agent process\n",
    "def print_run_trace(run_result):\n",
    "    print(\"\\n== DETAILED AGENT RUN TRACE ==\\n\")\n",
    "    \n",
    "    # Print basic info\n",
    "    print(f\"Total items generated: {len(run_result.new_items)}\")\n",
    "    print(f\"Model responses: {len(run_result.raw_responses)}\")\n",
    "    print(\"-\" * 80)\n",
    "    \n",
    "    # Loop through each item and print details based on item type\n",
    "    for i, item in enumerate(run_result.new_items):\n",
    "        item_type = getattr(item, 'type', 'unknown')\n",
    "        \n",
    "        print(f\"\\n[STEP {i+1}: {item_type}]\")\n",
    "        \n",
    "        if item_type == 'tool_call_item':\n",
    "            # Print tool call details\n",
    "            print(f\"  Agent: {item.agent.name}\")\n",
    "            raw_item = item.raw_item\n",
    "            print(f\"  Tool called: {raw_item.name}\")\n",
    "            print(f\"  Arguments: {raw_item.arguments}\")\n",
    "            \n",
    "        elif item_type == 'tool_call_output_item':\n",
    "            # Print tool output details\n",
    "            print(f\"  Agent: {item.agent.name}\")\n",
    "            print(f\"  Output type: {item.raw_item.get('type', 'unknown')}\")\n",
    "            \n",
    "            # Truncate long outputs for readability\n",
    "            output = item.output\n",
    "            if len(output) > 150:\n",
    "                output = output[:150] + \"...\"\n",
    "            print(f\"  Output: {output}\")\n",
    "            \n",
    "        elif item_type == 'message_output_item':\n",
    "            # Print message details\n",
    "            print(f\"  Agent: {item.agent.name}\")\n",
    "            raw_item = item.raw_item\n",
    "            \n",
    "            # Extract and format content\n",
    "            content = \"\"\n",
    "            if hasattr(raw_item, 'content') and raw_item.content:\n",
    "                for content_item in raw_item.content:\n",
    "                    if hasattr(content_item, 'text'):\n",
    "                        text = content_item.text\n",
    "                        if len(text) > 150:\n",
    "                            text = text[:150] + \"...\"\n",
    "                        content = text\n",
    "            \n",
    "            print(f\"  Role: {getattr(raw_item, 'role', 'unknown')}\")\n",
    "            print(f\"  Content: {content}\")\n",
    "            \n",
    "        else:\n",
    "            # For any other item types\n",
    "            print(f\"  Item details: {item}\")\n",
    "            \n",
    "        print(\"-\" * 80)\n",
    "    \n",
    "    # Print token usage information if available\n",
    "    print(\"\\n== TOKEN USAGE ==\")\n",
    "    total_input_tokens = 0\n",
    "    total_output_tokens = 0\n",
    "    \n",
    "    for i, response in enumerate(run_result.raw_responses):\n",
    "        if hasattr(response, 'usage'):\n",
    "            usage = response.usage\n",
    "            input_tokens = getattr(usage, 'input_tokens', 0)\n",
    "            output_tokens = getattr(usage, 'output_tokens', 0)\n",
    "            total_tokens = getattr(usage, 'total_tokens', 0)\n",
    "            \n",
    "            print(f\"Response {i+1}:\")\n",
    "            print(f\"  Input tokens: {input_tokens}\")\n",
    "            print(f\"  Output tokens: {output_tokens}\")\n",
    "            print(f\"  Total tokens: {total_tokens}\")\n",
    "            \n",
    "            total_input_tokens += input_tokens\n",
    "            total_output_tokens += output_tokens\n",
    "    \n",
    "    print(f\"\\nTotal input tokens: {total_input_tokens}\")\n",
    "    print(f\"Total output tokens: {total_output_tokens}\")\n",
    "    print(f\"Grand total tokens: {total_input_tokens + total_output_tokens}\")\n",
    "\n",
    "# Main function with detection of function calling issues\n",
    "async def ask(\n",
    "    question: str, \n",
    "    document_retriever=None, \n",
    "    language=\"English\"\n",
    "    ) -> Dict:\n",
    "    # Allow passing a document retriever if not defined globally\n",
    "    global my_document_retriever\n",
    "    if document_retriever is not None:\n",
    "        my_document_retriever = document_retriever\n",
    "    \n",
    "    # Create context with specified language\n",
    "    context = RAGContext(language=language)\n",
    "    \n",
    "    # First attempt: standard approach\n",
    "    with trace(\"Food Advisory Assistant - Standard Approach\"):\n",
    "        # Use a list for input items\n",
    "        input_items = [{\"content\": question, \"role\": \"user\"}]\n",
    "        \n",
    "        # Run the agent\n",
    "        run_result = await Runner.run(\n",
    "            rag_agent,\n",
    "            input=input_items,\n",
    "            context=context\n",
    "        )\n",
    "    \n",
    "    # Check if we got a proper answer or just a function call spec\n",
    "    is_function_call_text = False\n",
    "    if run_result.final_output:\n",
    "        # Check if the output looks like a raw function call\n",
    "        if run_result.final_output.startswith('{\"name\":') or \\\n",
    "           'diet_comparison' in run_result.final_output:\n",
    "            is_function_call_text = True\n",
    "    \n",
    "    # If the model returned a function call as text, use manual RAG approach\n",
    "    if is_function_call_text:\n",
    "        print(\"Detected function call specification in output. Switching to manual RAG process...\")\n",
    "        return await manual_rag_process(question, k=1)\n",
    "    \n",
    "    # Standard approach worked fine\n",
    "    return {\n",
    "        \"answer\": run_result.final_output,\n",
    "        \"run_result\": run_result,\n",
    "        \"context\": context\n",
    "    }\n",
    "\n",
    "# Example usage\n",
    "async def demo_rag():\n",
    "    question1 = \"Was passt besser zu mir: Low Carb oder Mittelmeerdi√§t?\"\n",
    "    question2 = \"Ich bin 1,75m gro√ü und wiege 95kg - wie hoch ist mein BMI?\"\n",
    "    question3 = \"Wie viele Kalorien brauche ich bei wenig Bewegung? Ich bin eine Frau, bin 30 Jahre, 170 cm gro√ü, mit 65 Kilo.\"\n",
    "    question4 = \"Ich bin laktoseintolerant - welche Di√§ten schlie√üen Milchprodukte aus?\"\n",
    "    question5 = \"Kannst du mein Ziel 'fitter werden' klarer formulieren?\"\n",
    "    result = await ask(question3, my_document_retriever)\n",
    "    \n",
    "    # Print the answer\n",
    "    print(\"ANSWER:\")\n",
    "    print(result[\"answer\"])\n",
    "    \n",
    "    # Use our detailed trace function\n",
    "    print_run_trace(result['run_result'])\n",
    "    \n",
    "    # Print context preview\n",
    "    context = result.get('context')\n",
    "    if context and hasattr(context, 'formatted_context'):\n",
    "        print(\"\\n== RETRIEVED CONTEXT ==\")\n",
    "        print(context.formatted_context)\n",
    "    \n",
    "    return 'sucess' #result\n",
    "\n",
    "# For Jupyter notebook execution\n",
    "await demo_rag()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
